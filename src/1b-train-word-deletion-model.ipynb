{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca99fe1-cff8-4595-82da-071a5c37f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878145d5-9523-4d78-8cee-e07d3b6e2933",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ec71f7-6c29-4aee-8951-ca0c91d60c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>options</th>\n",
       "      <th>answers</th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is well known that Albert Einstein was one ...</td>\n",
       "      <td>[[paper, food, water, air], [hold, take, carry...</td>\n",
       "      <td>[A, A, C, C, B, B, A, D]</td>\n",
       "      <td>high839</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Douglas was my cousin. I first met him when he...</td>\n",
       "      <td>[[day, week, month, year], [parent, cousin, un...</td>\n",
       "      <td>[D, B, A, D, C, B, B, A, C, D]</td>\n",
       "      <td>high2970</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two weeks before Christmas, Mother told me we ...</td>\n",
       "      <td>[[wanted, lacked, refused, prepared], [also, s...</td>\n",
       "      <td>[B, A, C, B, A, A, B, D, C, C, B, D, B, A, B, D]</td>\n",
       "      <td>high849</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1930, a young African American, Vivien T. T...</td>\n",
       "      <td>[[always, often, occasionally, never], [chance...</td>\n",
       "      <td>[D, B, A, C, B, A, D, C, B, A, D, C, B, A, D, ...</td>\n",
       "      <td>high251</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was born in New York City . My first seven y...</td>\n",
       "      <td>[[feeling, desire, taste, worry], [further, hi...</td>\n",
       "      <td>[B, C, D, A, C, A, B, D, C, A, B, D, C, B, C, ...</td>\n",
       "      <td>high2038</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7125</th>\n",
       "      <td>When I had something  _  to do, I used to ask ...</td>\n",
       "      <td>[[difficult, glad, good, happy], [spoke, talke...</td>\n",
       "      <td>[A, C, B, B, A, C, C, A, B, A, C]</td>\n",
       "      <td>middle2789</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>My name is Carla and I  have got  two sisters,...</td>\n",
       "      <td>[[me, I, my, I'm], [and, so, or, but], [also, ...</td>\n",
       "      <td>[B, D, D, B, C, C, D]</td>\n",
       "      <td>middle2788</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7127</th>\n",
       "      <td>A first-grade student named Vincent Butterfiel...</td>\n",
       "      <td>[[speaking, saying, telling, talking], [hair, ...</td>\n",
       "      <td>[C, A, C, B, D, D, C]</td>\n",
       "      <td>middle2762</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7128</th>\n",
       "      <td>One night a man came to my house. He said to m...</td>\n",
       "      <td>[[children, workers, farmers, cooks], [flowers...</td>\n",
       "      <td>[A, C, D, B, C, D, A, B]</td>\n",
       "      <td>middle2769</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>I did very poorly in school. My headmaster tho...</td>\n",
       "      <td>[[anything, something, everything, nothing], [...</td>\n",
       "      <td>[A, B, A, D, C, D, B, C, B]</td>\n",
       "      <td>middle2708</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7130 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  \\\n",
       "0     It is well known that Albert Einstein was one ...   \n",
       "1     Douglas was my cousin. I first met him when he...   \n",
       "2     Two weeks before Christmas, Mother told me we ...   \n",
       "3     In 1930, a young African American, Vivien T. T...   \n",
       "4     I was born in New York City . My first seven y...   \n",
       "...                                                 ...   \n",
       "7125  When I had something  _  to do, I used to ask ...   \n",
       "7126  My name is Carla and I  have got  two sisters,...   \n",
       "7127  A first-grade student named Vincent Butterfiel...   \n",
       "7128  One night a man came to my house. He said to m...   \n",
       "7129  I did very poorly in school. My headmaster tho...   \n",
       "\n",
       "                                                options  \\\n",
       "0     [[paper, food, water, air], [hold, take, carry...   \n",
       "1     [[day, week, month, year], [parent, cousin, un...   \n",
       "2     [[wanted, lacked, refused, prepared], [also, s...   \n",
       "3     [[always, often, occasionally, never], [chance...   \n",
       "4     [[feeling, desire, taste, worry], [further, hi...   \n",
       "...                                                 ...   \n",
       "7125  [[difficult, glad, good, happy], [spoke, talke...   \n",
       "7126  [[me, I, my, I'm], [and, so, or, but], [also, ...   \n",
       "7127  [[speaking, saying, telling, talking], [hair, ...   \n",
       "7128  [[children, workers, farmers, cooks], [flowers...   \n",
       "7129  [[anything, something, everything, nothing], [...   \n",
       "\n",
       "                                                answers      source  split  \\\n",
       "0                              [A, A, C, C, B, B, A, D]     high839  train   \n",
       "1                        [D, B, A, D, C, B, B, A, C, D]    high2970  train   \n",
       "2      [B, A, C, B, A, A, B, D, C, C, B, D, B, A, B, D]     high849  train   \n",
       "3     [D, B, A, C, B, A, D, C, B, A, D, C, B, A, D, ...     high251  train   \n",
       "4     [B, C, D, A, C, A, B, D, C, A, B, D, C, B, C, ...    high2038  train   \n",
       "...                                                 ...         ...    ...   \n",
       "7125                  [A, C, B, B, A, C, C, A, B, A, C]  middle2789   test   \n",
       "7126                              [B, D, D, B, C, C, D]  middle2788   test   \n",
       "7127                              [C, A, C, B, D, D, C]  middle2762   test   \n",
       "7128                           [A, C, D, B, C, D, A, B]  middle2769   test   \n",
       "7129                        [A, B, A, D, C, D, B, C, B]  middle2708   test   \n",
       "\n",
       "       level  \n",
       "0       high  \n",
       "1       high  \n",
       "2       high  \n",
       "3       high  \n",
       "4       high  \n",
       "...      ...  \n",
       "7125  middle  \n",
       "7126  middle  \n",
       "7127  middle  \n",
       "7128  middle  \n",
       "7129  middle  \n",
       "\n",
       "[7130 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_df = pd.read_parquet(\"../data/CLOTH/cloth.parquet\")\n",
    "in_df = in_df[in_df.source != \"high515\"] # This item has no options.\n",
    "in_df = in_df.reset_index(drop=True)\n",
    "in_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d010873-92ab-4222-ae02-0f7b670f6bbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get Correct Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bafdcae1-a4fd-4a4a-8af0-4982a8b76f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>options</th>\n",
       "      <th>answers</th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "      <th>level</th>\n",
       "      <th>answer_idx</th>\n",
       "      <th>correct_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is well known that Albert Einstein was one ...</td>\n",
       "      <td>[paper, food, water, air]</td>\n",
       "      <td>A</td>\n",
       "      <td>high839</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is well known that Albert Einstein was one ...</td>\n",
       "      <td>[hold, take, carry, bring]</td>\n",
       "      <td>A</td>\n",
       "      <td>high839</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is well known that Albert Einstein was one ...</td>\n",
       "      <td>[kindest, coolest, cleverest, coldest]</td>\n",
       "      <td>C</td>\n",
       "      <td>high839</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>cleverest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is well known that Albert Einstein was one ...</td>\n",
       "      <td>[think, talk, worry, set]</td>\n",
       "      <td>C</td>\n",
       "      <td>high839</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is well known that Albert Einstein was one ...</td>\n",
       "      <td>[suits, shoes, trousers, clothes]</td>\n",
       "      <td>B</td>\n",
       "      <td>high839</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "      <td>shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>I did very poorly in school. My headmaster tho...</td>\n",
       "      <td>[terrible, excellent, wrong, right]</td>\n",
       "      <td>C</td>\n",
       "      <td>middle2708</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "      <td>2</td>\n",
       "      <td>wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>I did very poorly in school. My headmaster tho...</td>\n",
       "      <td>[stayed, laughed, lived, studied]</td>\n",
       "      <td>D</td>\n",
       "      <td>middle2708</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "      <td>3</td>\n",
       "      <td>studied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>I did very poorly in school. My headmaster tho...</td>\n",
       "      <td>[Themselves, myself, himself, herself]</td>\n",
       "      <td>B</td>\n",
       "      <td>middle2708</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "      <td>1</td>\n",
       "      <td>myself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>I did very poorly in school. My headmaster tho...</td>\n",
       "      <td>[proud, rich, poor, happy]</td>\n",
       "      <td>C</td>\n",
       "      <td>middle2708</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "      <td>2</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>I did very poorly in school. My headmaster tho...</td>\n",
       "      <td>[cool, famous, clever, helpful]</td>\n",
       "      <td>B</td>\n",
       "      <td>middle2708</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "      <td>1</td>\n",
       "      <td>famous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99433 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  \\\n",
       "0     It is well known that Albert Einstein was one ...   \n",
       "0     It is well known that Albert Einstein was one ...   \n",
       "0     It is well known that Albert Einstein was one ...   \n",
       "0     It is well known that Albert Einstein was one ...   \n",
       "0     It is well known that Albert Einstein was one ...   \n",
       "...                                                 ...   \n",
       "7129  I did very poorly in school. My headmaster tho...   \n",
       "7129  I did very poorly in school. My headmaster tho...   \n",
       "7129  I did very poorly in school. My headmaster tho...   \n",
       "7129  I did very poorly in school. My headmaster tho...   \n",
       "7129  I did very poorly in school. My headmaster tho...   \n",
       "\n",
       "                                     options answers      source  split  \\\n",
       "0                  [paper, food, water, air]       A     high839  train   \n",
       "0                 [hold, take, carry, bring]       A     high839  train   \n",
       "0     [kindest, coolest, cleverest, coldest]       C     high839  train   \n",
       "0                  [think, talk, worry, set]       C     high839  train   \n",
       "0          [suits, shoes, trousers, clothes]       B     high839  train   \n",
       "...                                      ...     ...         ...    ...   \n",
       "7129     [terrible, excellent, wrong, right]       C  middle2708   test   \n",
       "7129       [stayed, laughed, lived, studied]       D  middle2708   test   \n",
       "7129  [Themselves, myself, himself, herself]       B  middle2708   test   \n",
       "7129              [proud, rich, poor, happy]       C  middle2708   test   \n",
       "7129         [cool, famous, clever, helpful]       B  middle2708   test   \n",
       "\n",
       "       level  answer_idx correct_answer  \n",
       "0       high           0          paper  \n",
       "0       high           0           hold  \n",
       "0       high           2      cleverest  \n",
       "0       high           2          worry  \n",
       "0       high           1          shoes  \n",
       "...      ...         ...            ...  \n",
       "7129  middle           2          wrong  \n",
       "7129  middle           3        studied  \n",
       "7129  middle           1         myself  \n",
       "7129  middle           2           poor  \n",
       "7129  middle           1         famous  \n",
       "\n",
       "[99433 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_df = in_df.explode([\"options\", \"answers\"])\n",
    "exploded_df[\"answer_idx\"] = exploded_df[\"answers\"].astype(\"category\").cat.codes\n",
    "exploded_df[\"correct_answer\"] = exploded_df.apply(lambda x: x[\"options\"][x[\"answer_idx\"]], axis=1)\n",
    "exploded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d0d1f8b-3ffe-499d-a1a1-c3c6156e6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    in_df.copy()\n",
    "    .drop(columns=[\"options\", \"answers\"])\n",
    "    .rename(columns={\n",
    "        \"article\": \"text_with_gaps\"\n",
    "    })\n",
    ")\n",
    "df[\"original_words\"] = (\n",
    "    exploded_df\n",
    "    .groupby(exploded_df.index)\n",
    "    .agg({\"correct_answer\": lambda x: x.tolist()})\n",
    "    .iloc[:, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b4c9a-a032-4986-b39c-585dcb0fa1c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Remove extra spaces around gaps\n",
    "\n",
    "Extra spaces will make it hard to handle token labels later. We should also be careful that we are not introducing an extra space before a piece of punctuation when we put the words back into place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b394d83-83ff-45f1-8366-65ec852d9287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pop singer Peng Tan has tasted the joys of being at the top of the world. He has also  _  life\\'s lows too. This  has taught  him that having a  _  picture of oneself is the key to  _  . \"I grew  _  at the peak of my career, and I began to lose faith when things turned  _  me,\" he said.\" \"Then I realized that dreams will  come true  only if I put myself in the  _  place.\" Peng, 29, will  _  at the Beijing Pop Festival at Chaoyang Park in Beijing held on September 8 to 9. He has  _  his first album Teen Spirit after he went solo from the rock band Dada. As the name  _  the album is about his reflection on his youth. \"The  _  years is a special restless period in life, with lots of confusion, sensations, with wise and ridiculous ideas colliding,\" said Peng. When younger, he first  _  of being a painter, until one day the  _  singing of Cui Jian lit up his passion, for rock music. In 1996, he became the  _  singer in the band Dada, which he set up with his  _  from junior school. Soon, they topped the music charts and  _  most of the \"\\'Best Newcomer of the Year\" awards. However, the good days didn\\'t last. The band  broke up  . Peng became depressed and began  _  his own ability. He then went to the Beijing Pop Festival last year and saw his favorite foreign band, Super Grass. This changed everything. After that, he was back on track and found his confidence. \"When you  _  to your position well in life, opportunities will come to you naturally.\" he said.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample().text_with_gaps.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20ceb01-2fe2-4f37-b274-bd3a62e8c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spacing(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Note that this is not perfect.\n",
    "    We would need much more complex processing to handle words next to quotation marks.\n",
    "    \"\"\"\n",
    "    # First standardize all gap sequences to single underscore\n",
    "    text = re.sub(r'_+', '_', text)\n",
    "    \n",
    "    # Remove spaces before gaps\n",
    "    text = re.sub(r'\\s+_', ' _', text)\n",
    "    \n",
    "    # Remove spaces after gaps when followed by punctuation\n",
    "    text = re.sub(r'_\\s+([.,!?;:])', r'_', text)\n",
    "    \n",
    "    # Remove spaces after gaps in other cases\n",
    "    text = re.sub(r'_\\s+', '_ ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b656070-24cf-4cdb-84ef-710873fde35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_with_gaps\"] = df[\"text_with_gaps\"].apply(normalize_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8f65a0d-5f7f-495d-864a-5a0635faf39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to our school. Our school is very big _ beautiful. There are two playgrounds and two football fields in _ school. There are also some _ in it and we can do many things in them. They are the Reading Club, the Drawing Club, the Swimming Club and so on. Many of _ are in the clubs. I am in the _ Club. I go to the club on Monday and Wednesday. On Monday afternoon, I go to the club and draw _ like apples and pears. On _ morning, I go to the club too. The art room _ modern. I like drawing there. Our school has an Open Day. The _ is 15 October. On that day, tea chers, students and parents are very _ We all like that day. What about your school? Can you tell me something about it?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text_with_gaps.sample().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b14bbc7-121f-4e92-a36d-8a3691ba5b2f",
   "metadata": {},
   "source": [
    "## Find Gap Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "906c7fb9-ee92-463f-bcb8-a76c899dabdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_with_gaps</th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "      <th>level</th>\n",
       "      <th>original_words</th>\n",
       "      <th>gap_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is well known that Albert Einstein was one ...</td>\n",
       "      <td>high839</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "      <td>[paper, hold, cleverest, worry, shoes, why, re...</td>\n",
       "      <td>[316, 380, 439, 659, 879, 980, 1079, 1123]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Douglas was my cousin. I first met him when he...</td>\n",
       "      <td>high2970</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "      <td>[year, cousin, meet, clothes, wear, same, save...</td>\n",
       "      <td>[81, 316, 383, 584, 653, 809, 863, 961, 1065, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two weeks before Christmas, Mother told me we ...</td>\n",
       "      <td>high849</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "      <td>[lacked, also, remove, complete, dawned, But, ...</td>\n",
       "      <td>[211, 263, 366, 460, 495, 569, 634, 675, 705, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1930, a young African American, Vivien T. T...</td>\n",
       "      <td>high251</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "      <td>[never, desire, secretly, developed, medicine,...</td>\n",
       "      <td>[171, 209, 315, 378, 429, 507, 609, 658, 722, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was born in New York City . My first seven y...</td>\n",
       "      <td>high2038</td>\n",
       "      <td>train</td>\n",
       "      <td>high</td>\n",
       "      <td>[desire, basic, chemistry, deciding, highly, e...</td>\n",
       "      <td>[135, 199, 300, 313, 418, 561, 671, 753, 819, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7125</th>\n",
       "      <td>When I had something _ to do, I used to ask my...</td>\n",
       "      <td>middle2789</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "      <td>[difficult, said, glad, invite, mother, yourse...</td>\n",
       "      <td>[21, 79, 114, 212, 328, 378, 542, 557, 636, 68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>My name is Carla and I  have got  two sisters,...</td>\n",
       "      <td>middle2788</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "      <td>[I, but, too, some, in, aren't, after]</td>\n",
       "      <td>[104, 125, 271, 293, 306, 400, 460]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7127</th>\n",
       "      <td>A first-grade student named Vincent Butterfiel...</td>\n",
       "      <td>middle2762</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "      <td>[telling, hair, without, expensive, scarves, o...</td>\n",
       "      <td>[120, 334, 477, 597, 635, 813, 839]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7128</th>\n",
       "      <td>One night a man came to my house. He said to m...</td>\n",
       "      <td>middle2769</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "      <td>[children, food, found, Where, answer, hungry,...</td>\n",
       "      <td>[79, 164, 221, 387, 426, 463, 556, 596]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>I did very poorly in school. My headmaster tho...</td>\n",
       "      <td>middle2708</td>\n",
       "      <td>test</td>\n",
       "      <td>middle</td>\n",
       "      <td>[anything, with, failed, daughter, wrong, stud...</td>\n",
       "      <td>[115, 184, 240, 310, 483, 522, 745, 764, 903]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7130 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text_with_gaps      source  split  \\\n",
       "0     It is well known that Albert Einstein was one ...     high839  train   \n",
       "1     Douglas was my cousin. I first met him when he...    high2970  train   \n",
       "2     Two weeks before Christmas, Mother told me we ...     high849  train   \n",
       "3     In 1930, a young African American, Vivien T. T...     high251  train   \n",
       "4     I was born in New York City . My first seven y...    high2038  train   \n",
       "...                                                 ...         ...    ...   \n",
       "7125  When I had something _ to do, I used to ask my...  middle2789   test   \n",
       "7126  My name is Carla and I  have got  two sisters,...  middle2788   test   \n",
       "7127  A first-grade student named Vincent Butterfiel...  middle2762   test   \n",
       "7128  One night a man came to my house. He said to m...  middle2769   test   \n",
       "7129  I did very poorly in school. My headmaster tho...  middle2708   test   \n",
       "\n",
       "       level                                     original_words  \\\n",
       "0       high  [paper, hold, cleverest, worry, shoes, why, re...   \n",
       "1       high  [year, cousin, meet, clothes, wear, same, save...   \n",
       "2       high  [lacked, also, remove, complete, dawned, But, ...   \n",
       "3       high  [never, desire, secretly, developed, medicine,...   \n",
       "4       high  [desire, basic, chemistry, deciding, highly, e...   \n",
       "...      ...                                                ...   \n",
       "7125  middle  [difficult, said, glad, invite, mother, yourse...   \n",
       "7126  middle             [I, but, too, some, in, aren't, after]   \n",
       "7127  middle  [telling, hair, without, expensive, scarves, o...   \n",
       "7128  middle  [children, food, found, Where, answer, hungry,...   \n",
       "7129  middle  [anything, with, failed, daughter, wrong, stud...   \n",
       "\n",
       "                                          gap_positions  \n",
       "0            [316, 380, 439, 659, 879, 980, 1079, 1123]  \n",
       "1     [81, 316, 383, 584, 653, 809, 863, 961, 1065, ...  \n",
       "2     [211, 263, 366, 460, 495, 569, 634, 675, 705, ...  \n",
       "3     [171, 209, 315, 378, 429, 507, 609, 658, 722, ...  \n",
       "4     [135, 199, 300, 313, 418, 561, 671, 753, 819, ...  \n",
       "...                                                 ...  \n",
       "7125  [21, 79, 114, 212, 328, 378, 542, 557, 636, 68...  \n",
       "7126                [104, 125, 271, 293, 306, 400, 460]  \n",
       "7127                [120, 334, 477, 597, 635, 813, 839]  \n",
       "7128            [79, 164, 221, 387, 426, 463, 556, 596]  \n",
       "7129      [115, 184, 240, 310, 483, 522, 745, 764, 903]  \n",
       "\n",
       "[7130 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_gap_positions(text: str) -> list[int]:\n",
    "    positions = []\n",
    "    for match in re.finditer(r'_', text):\n",
    "        positions.append(match.start())\n",
    "    return positions\n",
    "\n",
    "df[\"gap_positions\"] = df[\"text_with_gaps\"].apply(find_gap_positions)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96b63fc7-d55d-4db9-ba50-92cfd12de163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "One day a few years ago we had a guest of the uninvited variety. In fact, this uninvited guest was a bird--- a(n) sparrow to be more precise . \"What's that?\" I asked when I first heard the thump . \"It sounds like Joe is outside playing basketball,\" my wife, Anita, said. She paused and listened more devotedly. \"It's coming from the garage\" she said. \"Maybe it's one of the little kids \". We rushed out the door. Jonathan, our youngest, was easy to make trouble \"If he's making holes in the wall again...\" I said as I searched there. No children at all. But there was that sound again, coming from right up there. And that's when I spotted the sparrow. It was flying anxiously just inches below the ceiling. It was clearly trying to  get out  , but couldn't see that the way out wasn't up, but down and out through the open door So the bird continued beating its wings and hitting its head against the ceiling \"Poor thing,\" Anita said. \"It must be terrified\" \"Well, maybe it's because of me,\" I said as I moved toward it. I tried to show the bird how to glide down a few feet so it could get outside, but that only seemed to frighten it more. \"Why don't we just leave\" Anita suggested. \"I'm sure he'll succeed eventually.\" So we went back into the house, where we continued to hear the ongoing struggle. Then suddenly, it was silent We looked into the garage, and our uninvited guest was gone \"See?\" Anita said. \"I told you he would make it.\" \"Yeah,\" I said. \"But how many knocks on the head did it cost him?\" I've thought about that little sparrow through the years. Just like that sparrow, we often meet situations we don't know how to  deal with  . Born to go upward, we don't even consider the possibility that something good might happen if we stop flapping around and just glide down a little bit.\n",
      "================================================================================\n",
      "Christmas was coming. A lot of farmers were going to town. They hoped to sell some vegetables, fruit and meat in the market. And then they were going to buy some presents for their families. A bus came. They tried to  get on  . Robert, a strong young man, rushed in first. He occupied two seats one for his girl friend Mable and the other for himself. The bus started. Robert had a look around the bus. He saw a lot of people standing there. There were some old men among them. He hurried to  close  his eyes. Mable found it and thought he felt terrible and asked, \"What's wrong with you, dear?\"\" Nothing\"answered the kind-hearted young man. \"I can't bear to see the poor old men!\"\n"
     ]
    }
   ],
   "source": [
    "# Testing gap-replacement logic\n",
    "\n",
    "for row in df.sample(2).itertuples():\n",
    "    text = row.text_with_gaps\n",
    "    offset = 0\n",
    "    for word, pos in zip(row.original_words, row.gap_positions):\n",
    "        pos_ = pos + offset\n",
    "        text = text[:pos_] + word + text[pos_ + 1:]\n",
    "        offset += len(word) - 1 # minus 1 because the underscore has length 1\n",
    "    print(\"=\"*80)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba144e-c5c9-420f-90d9-4f11ff6bbd21",
   "metadata": {},
   "source": [
    "## Define ClozeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eac0e49-d8ec-4f9c-8ac9-4fd235c1b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClozeDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer, max_length=512):\n",
    "        \"\"\"        \n",
    "        Expected DataFrame columns:\n",
    "        - text_with_gaps: Text with underscores where words were removed\n",
    "        - original_words: String or list of removed words\n",
    "        - gap_positions: String or list of gap positions (integers)\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        adjusted_gap_positions = []\n",
    "        \n",
    "        # Reconstruct original text by replacing underscores with original words\n",
    "        text = row['text_with_gaps']\n",
    "        offset = 0\n",
    "        for word, pos in zip(row['original_words'], row['gap_positions']):\n",
    "            pos_ = pos + offset\n",
    "            adjusted_gap_positions.append(pos_) # We need this for constructing the labels\n",
    "            text = text[:pos_] + word + text[pos_ + 1:]\n",
    "            offset += len(word) - 1 # minus 1 because the underscore has length 1\n",
    "        \n",
    "        # Tokenize the original text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Create labels: 1 for tokens that correspond to gap words, 0 for others\n",
    "        labels = torch.zeros(len(encoding['input_ids'][0]))\n",
    "        offset_mapping = encoding['offset_mapping'][0]\n",
    "        \n",
    "        # For each original word that should be a gap\n",
    "        for word, start_pos in zip(row['original_words'], adjusted_gap_positions):\n",
    "            end_pos = start_pos + len(word)\n",
    "            # Find which token(s) correspond to this word\n",
    "            for idx, (token_start, token_end) in enumerate(offset_mapping):\n",
    "                if ( # a token starts inside the target word\n",
    "                    (token_start.item() >= start_pos and token_start.item() < end_pos)\n",
    "                    or # a token ends inside the target word\n",
    "                    (token_end.item() > start_pos and token_end.item() <= end_pos) \n",
    "                ):\n",
    "                    labels[idx] = 1\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'][0],\n",
    "            'attention_mask': encoding['attention_mask'][0],\n",
    "            'labels': labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bace49-ce5e-4f3e-964e-bb6038005d87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Define compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cb48f9e-51b4-4866-9c90-2b9b9d6dcdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    # Flatten the arrays and mask the padding (-100) tokens\n",
    "    true_predictions = predictions.flatten()\n",
    "    true_labels = labels.flatten()\n",
    "    mask = true_labels != -100\n",
    "    true_predictions = true_predictions[mask]\n",
    "    true_labels = true_labels[mask]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, true_predictions, zero_division=0),\n",
    "        \"recall\": recall_score(true_labels, true_predictions, zero_division=0),\n",
    "        \"f1\": f1_score(true_labels, true_predictions, zero_division=0),\n",
    "        \"accuracy\": accuracy_score(true_labels, true_predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f3c356-d3e4-47d8-b067-c291750ab258",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "156ca5ca-06dc-4405-8e73-4d01c4b1c803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0831, 'grad_norm': 0.15343379974365234, 'learning_rate': 1.5162070633768748e-05, 'epoch': 0.7256894049346879}\n",
      "{'eval_loss': 0.06652272492647171, 'eval_precision': 0.7896386045540004, 'eval_recall': 0.31154702052254185, 'eval_f1': 0.4468085106382979, 'eval_accuracy': 0.9775138376383764, 'eval_runtime': 48.2407, 'eval_samples_per_second': 16.853, 'eval_steps_per_second': 2.114, 'epoch': 1.0}\n",
      "{'loss': 0.0734, 'grad_norm': 0.12325280904769897, 'learning_rate': 1.0324141267537495e-05, 'epoch': 1.4513788098693758}\n",
      "{'eval_loss': 0.0652344822883606, 'eval_precision': 0.7893037336024218, 'eval_recall': 0.322344020440122, 'eval_f1': 0.457748127340824, 'eval_accuracy': 0.9777396602091021, 'eval_runtime': 48.4988, 'eval_samples_per_second': 16.763, 'eval_steps_per_second': 2.103, 'epoch': 2.0}\n",
      "{'loss': 0.0694, 'grad_norm': 0.1444166600704193, 'learning_rate': 5.486211901306241e-06, 'epoch': 2.1770682148040637}\n",
      "{'loss': 0.0664, 'grad_norm': 0.14548803865909576, 'learning_rate': 6.48282535074988e-07, 'epoch': 2.9027576197387517}\n",
      "{'eval_loss': 0.06532557308673859, 'eval_precision': 0.784548850009829, 'eval_recall': 0.3289376081760488, 'eval_f1': 0.46353077816492455, 'eval_accuracy': 0.977806926506765, 'eval_runtime': 48.593, 'eval_samples_per_second': 16.731, 'eval_steps_per_second': 2.099, 'epoch': 3.0}\n",
      "{'train_runtime': 1561.6495, 'train_samples_per_second': 10.589, 'train_steps_per_second': 1.324, 'train_loss': 0.0730062285424663, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "def train_cloze_model(\n",
    "    train_df: pd.DataFrame,\n",
    "    eval_df: pd.DataFrame,\n",
    "    model_name=\"microsoft/deberta-v3-base\",\n",
    "    output_dir=\"../bin\",\n",
    "):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        train_df: Training DataFrame with columns [text_with_gaps, original_words, gap_positions]\n",
    "        eval_df: Evaluation DataFrame with same columns\n",
    "        model_name: Name of the pretrained model to use\n",
    "        output_dir: Directory to save the model\n",
    "    \"\"\"\n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2  # Binary classification: gap or no gap\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ClozeDataset(train_df, tokenizer)\n",
    "    eval_dataset = ClozeDataset(eval_df, tokenizer)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=DataCollatorForTokenClassification(tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save the final model\n",
    "    trainer.save_model(\"../bin/cloze-model\")\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = train_cloze_model(\n",
    "    df[df[\"split\"] == \"train\"],\n",
    "    df[df[\"split\"] == \"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fcc0b2-1393-48f4-9a47-81b87ffde703",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9533f5d8-9885-484e-b271-11293efe0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cloze(text, model, tokenizer, threshold=0.5):\n",
    "    \"\"\"Generate a cloze exercise from input text.\"\"\"\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        return_offsets_mapping=True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    encoding.to('cuda')\n",
    "    \n",
    "    offset_mapping = encoding.pop('offset_mapping')\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "        predictions = (probabilities[0, :, 1] > threshold).cpu().numpy()\n",
    "\n",
    "    print(outputs)\n",
    "    \n",
    "    # Convert predictions to gaps in the text\n",
    "    offset_mapping = offset_mapping[0].cpu().numpy()\n",
    "    text_list = list(text)\n",
    "\n",
    "    # Replace predicted tokens with underscores\n",
    "    for idx, pred in enumerate(predictions):\n",
    "        if pred:\n",
    "            start, end = offset_mapping[idx]\n",
    "            if start < len(text_list):  # Check if within text bounds\n",
    "                text_list[start:end] = ' ' + '_' * (end - start - 1)\n",
    "    \n",
    "    return ''.join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "612f2fc9-b5c9-4b78-b777-06244ca20dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenClassifierOutput(loss=None, logits=tensor([[[ 1.5748, -2.4767],\n",
      "         [ 2.9657, -3.0802],\n",
      "         [ 2.4212, -2.4601],\n",
      "         ...,\n",
      "         [ 2.7631, -3.1936],\n",
      "         [ 2.7631, -3.1936],\n",
      "         [ 2.7631, -3.1936]]], device='cuda:0'), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The hugely popular video app was taken offline Saturday night in compliance with a law that effectively banned the service nationwide unless it splits off from ByteDance, its China-based owner. Last week, the Supreme Court ______ the law.\\nOn Saturday, Google and Apple removed the app from their stores, a ___________ of the ban, which also forbids web-hosting companies from providing back-end support to the app.\\nWhen Biden officials said they would leave enforcement of the law up to the Trump administration, web-hosting services were not _________ they would not be prosecuted. The law outlines stiff penalties for violations that could cost the companies billions.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = '''Chevron's comprehensive training program ensures operators progress from new hires to Fully Qualified Operators (FQO) through a structured, multi-year process involving orientation, on-the-job training, and assessments. FQOs continue training for additional roles, with records meticulously maintained. Control Room Operators (CROs) and Head Operators (HOs) undergo specialized training, including console and simulator sessions, to maintain qualifications. Requalification processes address absences, ensuring operators remain current. Interns receive supervised exposure to operations, potentially transitioning to trainees. Unit School Instructors, selected for their expertise, facilitate training. The program emphasizes continuous learning and adaptation to procedural changes, documented via electronic systems to support operator competence and advancement.'''\n",
    "example_text = '''The hugely popular video app was taken offline Saturday night in compliance with a law that effectively banned the service nationwide unless it splits off from ByteDance, its China-based owner. Last week, the Supreme Court upheld the law.\n",
    "On Saturday, Google and Apple removed the app from their stores, a requirement of the ban, which also forbids web-hosting companies from providing back-end support to the app.\n",
    "When Biden officials said they would leave enforcement of the law up to the Trump administration, web-hosting services were not confident they would not be prosecuted. The law outlines stiff penalties for violations that could cost the companies billions.'''\n",
    "\n",
    "generate_cloze(example_text, model, tokenizer, threshold=0.50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
