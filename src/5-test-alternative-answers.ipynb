{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef035409-0d4f-4085-883a-42523e07e2a1",
   "metadata": {},
   "source": [
    "# Generate Alternative Answers\n",
    "\n",
    "Will generate alternative answers by finding topk or min_prob predictions for each gap.\n",
    "\n",
    "Using the test data from human raters, will find optimal values for topk/min_prob.\n",
    "\n",
    "Optimal alternative answers will overlap with human responses, especially answers that multiple humans suggested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed39f237-3bfa-40d0-bfbd-b94eacfac367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357b6371-5ef8-4038-80d6-2af62e3576dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy transformers tqdm seaborn pandas numpy torch --quiet\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8bb68-f6ef-473b-8312-8d8009802517",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Combine the human annotations with the generated cloze exercises and source texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2e34bf-5070-4a1a-bea7-5ddac9e1524b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>page</th>\n",
       "      <th>summary</th>\n",
       "      <th>markdown</th>\n",
       "      <th>text</th>\n",
       "      <th>contextuality</th>\n",
       "      <th>contextuality_plus</th>\n",
       "      <th>keyword</th>\n",
       "      <th>passageId</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>method</th>\n",
       "      <th>score</th>\n",
       "      <th>timeSpent</th>\n",
       "      <th>answers</th>\n",
       "      <th>correctAnswers</th>\n",
       "      <th>annotations</th>\n",
       "      <th>holisticScore</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>annotation_counts</th>\n",
       "      <th>pct_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>research-methods-in-psychology-demo</td>\n",
       "      <td>9-generating-good-research-questions-1</td>\n",
       "      <td>When developing a research idea, transforming ...</td>\n",
       "      <td>&lt;i-callout variant=\"info\" title=\"Learning Obje...</td>\n",
       "      <td>Learning Objectives\\n\\n1. Describe some techni...</td>\n",
       "      <td>{'text': 'When developing a research idea, tra...</td>\n",
       "      <td>{'text': 'When developing a research idea, tra...</td>\n",
       "      <td>{'text': 'When developing a research idea, tra...</td>\n",
       "      <td>3</td>\n",
       "      <td>3tX80XR8HgqetI32rkil</td>\n",
       "      <td>...</td>\n",
       "      <td>contextuality_plus</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>469.855</td>\n",
       "      <td>[achieved, researchers, conceptualizing, study...</td>\n",
       "      <td>[achieved, researchers, conceptualizing, explo...</td>\n",
       "      <td>[sentence, source, sentence, sentence, sentenc...</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-06-02T21:59:37.864Z</td>\n",
       "      <td>{'sentence': 4, 'source': 4, 'unpredictable': 1}</td>\n",
       "      <td>44.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>research-methods-in-psychology</td>\n",
       "      <td>1-methods-of-knowing</td>\n",
       "      <td>The text discusses various methods of acquirin...</td>\n",
       "      <td>&lt;i-callout variant=\"info\" title=\"Learning Obje...</td>\n",
       "      <td>Learning Objectives\\n\\n1. Describe the 5 metho...</td>\n",
       "      <td>{'text': 'The text discusses various methods o...</td>\n",
       "      <td>{'text': 'The text discusses various methods o...</td>\n",
       "      <td>{'text': 'The text discusses various methods o...</td>\n",
       "      <td>5</td>\n",
       "      <td>68bhaXDbcVAwvyqfLgM6</td>\n",
       "      <td>...</td>\n",
       "      <td>contextuality_plus</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>307.150</td>\n",
       "      <td>[instincts, involves, shows, incorrect, based,...</td>\n",
       "      <td>[instincts, involves, shows, incorrect, based,...</td>\n",
       "      <td>[source, sentence, sentence, source, sentence,...</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-10T23:29:56.864Z</td>\n",
       "      <td>{'source': 4, 'sentence': 3, 'unpredictable': 2}</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 volume  \\\n",
       "16  research-methods-in-psychology-demo   \n",
       "28       research-methods-in-psychology   \n",
       "\n",
       "                                      page  \\\n",
       "16  9-generating-good-research-questions-1   \n",
       "28                    1-methods-of-knowing   \n",
       "\n",
       "                                              summary  \\\n",
       "16  When developing a research idea, transforming ...   \n",
       "28  The text discusses various methods of acquirin...   \n",
       "\n",
       "                                             markdown  \\\n",
       "16  <i-callout variant=\"info\" title=\"Learning Obje...   \n",
       "28  <i-callout variant=\"info\" title=\"Learning Obje...   \n",
       "\n",
       "                                                 text  \\\n",
       "16  Learning Objectives\\n\\n1. Describe some techni...   \n",
       "28  Learning Objectives\\n\\n1. Describe the 5 metho...   \n",
       "\n",
       "                                        contextuality  \\\n",
       "16  {'text': 'When developing a research idea, tra...   \n",
       "28  {'text': 'The text discusses various methods o...   \n",
       "\n",
       "                                   contextuality_plus  \\\n",
       "16  {'text': 'When developing a research idea, tra...   \n",
       "28  {'text': 'The text discusses various methods o...   \n",
       "\n",
       "                                              keyword  passageId  \\\n",
       "16  {'text': 'When developing a research idea, tra...          3   \n",
       "28  {'text': 'The text discusses various methods o...          5   \n",
       "\n",
       "                      id  ...              method      score  timeSpent  \\\n",
       "16  3tX80XR8HgqetI32rkil  ...  contextuality_plus  44.444444    469.855   \n",
       "28  68bhaXDbcVAwvyqfLgM6  ...  contextuality_plus  77.777778    307.150   \n",
       "\n",
       "                                              answers  \\\n",
       "16  [achieved, researchers, conceptualizing, study...   \n",
       "28  [instincts, involves, shows, incorrect, based,...   \n",
       "\n",
       "                                       correctAnswers  \\\n",
       "16  [achieved, researchers, conceptualizing, explo...   \n",
       "28  [instincts, involves, shows, incorrect, based,...   \n",
       "\n",
       "                                          annotations holisticScore  \\\n",
       "16  [sentence, source, sentence, sentence, sentenc...             3   \n",
       "28  [source, sentence, sentence, source, sentence,...             2   \n",
       "\n",
       "                   timestamp  \\\n",
       "16  2025-06-02T21:59:37.864Z   \n",
       "28  2025-05-10T23:29:56.864Z   \n",
       "\n",
       "                                   annotation_counts pct_correct  \n",
       "16  {'sentence': 4, 'source': 4, 'unpredictable': 1}   44.444444  \n",
       "28  {'source': 4, 'sentence': 3, 'unpredictable': 2}   77.777778  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df = (\n",
    "    # Human responses and ratings to a selection of Cloze exercises\n",
    "    pd.read_csv(\"../data/testResults_from_2025-05-07.csv\")\n",
    "    # Convert dictionaries to lists\n",
    "    .assign(\n",
    "        answers=lambda x: x[\"answers\"].apply(\n",
    "            lambda row: list(json.loads(row).values())\n",
    "        ),\n",
    "        correctAnswers=lambda x: x[\"correctAnswers\"].apply(\n",
    "            lambda row: list(json.loads(row).values())\n",
    "        ),\n",
    "        annotation_counts=lambda x: x[\"annotations\"].apply(\n",
    "            lambda row: Counter(json.loads(row).values())\n",
    "        ),\n",
    "        annotations=lambda x: x[\"annotations\"].apply(\n",
    "            lambda row: list(json.loads(row).values())\n",
    "        ),\n",
    "    )\n",
    "    # Calculate percentage correct\n",
    "    .assign(\n",
    "        pct_correct=lambda x: x.apply(\n",
    "            lambda row: sum(\n",
    "                a == c for a, c in zip(row[\"answers\"], row[\"correctAnswers\"])\n",
    "            )\n",
    "            / len(row[\"answers\"])\n",
    "            * 100,\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "cloze_df = pd.read_json(\n",
    "    \"../results/cloze_exercises_kl_divergence.jsonl\", lines=True\n",
    ").assign(passageId=lambda x: x.index + 1)\n",
    "\n",
    "df = pd.merge(cloze_df, annotations_df, on=\"passageId\").query(\n",
    "    'method == \"contextuality_plus\"'\n",
    ")\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164acfc-8983-44ba-b579-063f95027fba",
   "metadata": {},
   "source": [
    "# Initialize Gapper\n",
    "\n",
    "Just using this for a few of its utility methods..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ba1b20-275f-462a-8e0a-42e87fb97ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualityGapper:\n",
    "    def __init__(self, model_name: str = \"answerdotai/ModernBERT-large\"):\n",
    "        # Load SpaCy for sentence splitting and preprocessing\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Load model and tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.min_blank_distance = 7  # Minimum distance between blanks\n",
    "\n",
    "        # Minimum log-predictability of alternatives\n",
    "        self.min_predictability = np.log(0.05)\n",
    "\n",
    "        # Part-of-Speech Blacklist (do not delete these words)\n",
    "        self.blacklist = [\n",
    "            \"PROPN\",  # Proper nouns\n",
    "            \"NUM\",  # Numbers\n",
    "            \"PUNCT\",  # Punctuation\n",
    "            \"SYM\",  # Symbols\n",
    "            \"X\",  # Other\n",
    "        ]\n",
    "\n",
    "    def _get_leading_ws_tokens(self, doc: Doc) -> list[str]:\n",
    "        \"\"\"The ModernBERT Tokenizer will work fine if we give it tokens with leading spaces.\n",
    "        SpaCy normally handles whitespace in terms of trailing space.\"\"\"\n",
    "        if not len(doc):\n",
    "            return [\"\"]\n",
    "\n",
    "        tokens = [doc[0].text]\n",
    "        # For tokens after the 0th, prepend trailing whitespace from the previous token.\n",
    "        tokens += [doc[i - 1].whitespace_ + doc[i].text for i in range(1, len(doc))]\n",
    "        return tokens\n",
    "\n",
    "    def get_token_mappings(self, tokens: list[str]) -> dict[int, list[int]]:\n",
    "        \"\"\"Get mappings between word positions and token positions\"\"\"\n",
    "        # Tokenize while keeping track of word IDs\n",
    "        tokenized = self.tokenizer(\n",
    "            tokens, return_tensors=\"pt\", is_split_into_words=True\n",
    "        )\n",
    "        word_ids = tokenized.word_ids()\n",
    "\n",
    "        # Create mapping from word position to token positions\n",
    "        word_to_tokens = defaultdict(list)\n",
    "\n",
    "        for token_idx, word_idx in enumerate(word_ids):\n",
    "            if word_idx is not None:\n",
    "                word_to_tokens[word_idx].append(token_idx)\n",
    "\n",
    "        return word_to_tokens\n",
    "\n",
    "    def get_masked_logits(\n",
    "        self, tokens: list[str], mask_idx: int\n",
    "    ) -> tuple[torch.Tensor, int]:\n",
    "        \"\"\"Get model logits for a masked position in text\"\"\"\n",
    "        # Get the word tokens and their alignment info\n",
    "        word_to_tokens = self.get_token_mappings(tokens)\n",
    "\n",
    "        # Find all token positions for the word we want to mask\n",
    "        token_positions = word_to_tokens[mask_idx]\n",
    "\n",
    "        # Create masked version of the text\n",
    "        input_ids = self.tokenizer(\n",
    "            tokens, is_split_into_words=True, return_tensors=\"pt\"\n",
    "        ).input_ids[0]\n",
    "        masked_ids = input_ids.clone()\n",
    "\n",
    "        # ID of the first subword token that we masked\n",
    "        first_token_id = input_ids[token_positions[0]]\n",
    "\n",
    "        # Mask all tokens corresponding to our target word\n",
    "        masked_ids[token_positions] = self.tokenizer.mask_token_id\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = self.model(input_ids.unsqueeze(0).to(self.device))\n",
    "\n",
    "        # Get logits\n",
    "        logits = outputs.logits[0, token_positions, :]\n",
    "\n",
    "        return logits, first_token_id\n",
    "\n",
    "    def get_contextuality_score(\n",
    "        self,\n",
    "        page_doc: Doc,\n",
    "        summary_doc: Doc,\n",
    "        sent: Span,\n",
    "        tok: Token,\n",
    "        method: str = \"kl\",\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate contextuality score for a word position using full page context\n",
    "\n",
    "        Args:\n",
    "            page_doc: The full page text as a spaCy Doc\n",
    "            summary_doc: The summary text as a spaCy Doc\n",
    "            sent: The sentence from the summary containing the token\n",
    "            tok: The token from the summary to evaluate\n",
    "            method: \"kl\" for kl-divergence or \"contextuality\" for contextuality score\n",
    "\n",
    "        Returns:\n",
    "            Contextuality score\n",
    "        \"\"\"\n",
    "\n",
    "        # Get logits for both full text and sentence text\n",
    "        # For the full text context, we use the page + summary\n",
    "        full_toks = self._get_leading_ws_tokens(page_doc) + self._get_leading_ws_tokens(\n",
    "            summary_doc\n",
    "        )\n",
    "        full_pos = len(page_doc) + tok.i  # Position of token in full document\n",
    "        full_logits, word_id = self.get_masked_logits(full_toks, full_pos)\n",
    "\n",
    "        # For the local context, we use just the sentence from the summary\n",
    "        sent_pos = tok.i - sent.start  # Position of token in the sentence\n",
    "        sent_logits, _ = self.get_masked_logits([tok.text for tok in sent], sent_pos)\n",
    "\n",
    "        # Calculate probabilities using first sub-word token\n",
    "        full_probs = torch.softmax(full_logits[0], dim=0)\n",
    "        sent_probs = torch.softmax(sent_logits[0], dim=0)\n",
    "\n",
    "        p = full_probs[word_id]\n",
    "        q = sent_probs[word_id]\n",
    "\n",
    "        if method == \"kl\":\n",
    "            # KL-divergence is p*log(p/q)\n",
    "            score = float(p * torch.log2(p / q))\n",
    "        elif method == \"contextuality\":\n",
    "            # Contextuality is distance between full-text and sentence probability\n",
    "            score = float(p - q)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown method.\")\n",
    "\n",
    "        return score\n",
    "\n",
    "    def choose_blank_positions(\n",
    "        self, page_doc: Doc, summary_doc: Doc, num_blanks: int\n",
    "    ) -> list[int]:\n",
    "        \"\"\"Choose positions to blank in the summary based on contextuality scores with full page\"\"\"\n",
    "        scores = []\n",
    "        valid_positions = []\n",
    "\n",
    "        page_lemmas = {tok.lemma_ for tok in page_doc}\n",
    "\n",
    "        # Calculate scores for each position in the summary\n",
    "        for i, sent in enumerate(summary_doc.sents):\n",
    "            if i == 0:\n",
    "                continue  # Skip first sentence\n",
    "            for tok in sent:\n",
    "                if (\n",
    "                    len(tok.text) < 3\n",
    "                    or tok.pos_ in self.blacklist\n",
    "                    or tok.is_stop\n",
    "                    or not tok.text.isalpha()\n",
    "                    or tok.lemma_ not in page_lemmas\n",
    "                ):\n",
    "                    scores.append(-float(\"inf\"))\n",
    "                else:\n",
    "                    # Calculate contextuality using both the full page and summary\n",
    "                    score = self.get_contextuality_score(\n",
    "                        page_doc, summary_doc, sent, tok\n",
    "                    )\n",
    "                    scores.append(score)\n",
    "                valid_positions.append(tok.i)\n",
    "\n",
    "        # Convert to numpy for easier manipulation\n",
    "        scores = np.array(scores)\n",
    "\n",
    "        # Choose positions greedily while maintaining minimum distance\n",
    "        positions = []\n",
    "        for _ in range(num_blanks):\n",
    "            if np.all(scores == -float(\"inf\")):\n",
    "                break\n",
    "\n",
    "            # Choose highest scoring position\n",
    "            idx = np.argmax(scores)\n",
    "            pos = valid_positions[idx]\n",
    "            positions.append(pos)\n",
    "\n",
    "            # Zero out scores within minimum distance\n",
    "            start = max(0, idx - self.min_blank_distance)\n",
    "            end = min(len(scores), idx + self.min_blank_distance + 1)\n",
    "            scores[start:end] = -float(\"inf\")\n",
    "\n",
    "        return sorted(positions)\n",
    "\n",
    "    def get_alternates(self, tokens: list[str], topk=5) -> list[dict]:\n",
    "        \"\"\"Get top k predictions for the masked positions in tokens\n",
    "\n",
    "        Returns:\n",
    "            List of dictionaries, one per masked position, with candidate words and their probabilities\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "\n",
    "        # Find all mask positions\n",
    "        mask_positions = [i for i, token in enumerate(tokens) if token == \"[MASK]\"]\n",
    "\n",
    "        for mask_pos in mask_positions:\n",
    "            word_candidates = {}\n",
    "\n",
    "            # Try different mask lengths (1, 2, or 3 tokens)\n",
    "            for mask_length in range(1, 4):\n",
    "                # Replace the single mask with multiple if needed\n",
    "                masked_tokens = (\n",
    "                    tokens[:mask_pos]\n",
    "                    + [\"[MASK]\"] * mask_length\n",
    "                    + tokens[mask_pos + 1 :]\n",
    "                )\n",
    "\n",
    "                # Get initial predictions for first token\n",
    "                current_candidates = []\n",
    "                logits, _ = self.get_masked_logits(masked_tokens, mask_pos)\n",
    "                probs = torch.softmax(logits[0], dim=0)\n",
    "                top_values, top_indices = torch.topk(probs, topk)\n",
    "\n",
    "                # Start with first token candidates\n",
    "                for idx, prob in zip(top_indices.tolist(), top_values.tolist()):\n",
    "                    current_candidates.append(([idx], prob))\n",
    "\n",
    "                # Build up multi-token predictions if needed\n",
    "                for token_idx in range(1, mask_length):\n",
    "                    new_candidates = []\n",
    "                    for token_ids, prob in current_candidates:\n",
    "                        # Fill in what we've predicted so far\n",
    "                        partial_filled = tokens.copy()\n",
    "                        filled_text = self.tokenizer.decode(token_ids)\n",
    "                        remaining_masks = mask_length - token_idx\n",
    "\n",
    "                        partial_filled = (\n",
    "                            tokens[:mask_pos]\n",
    "                            + [filled_text]\n",
    "                            + [\"[MASK]\"] * remaining_masks\n",
    "                            + tokens[mask_pos + 1 :]\n",
    "                        )\n",
    "\n",
    "                        # Get prediction for next position\n",
    "                        next_logits, _ = self.get_masked_logits(\n",
    "                            partial_filled, mask_pos + 1\n",
    "                        )\n",
    "                        next_probs = torch.softmax(next_logits[0], dim=0)\n",
    "                        next_values, next_indices = torch.topk(next_probs, 1)\n",
    "\n",
    "                        # Add to candidates\n",
    "                        new_token_ids = token_ids + [next_indices[0].item()]\n",
    "                        new_prob = prob * next_values[0].item()\n",
    "                        new_candidates.append((new_token_ids, new_prob))\n",
    "\n",
    "                    current_candidates = new_candidates\n",
    "\n",
    "                # Add final decoded words\n",
    "                for token_ids, prob in current_candidates:\n",
    "                    word = self.tokenizer.decode(token_ids).strip()\n",
    "                    if \" \" in word:\n",
    "                        # Word contains a space (is actually multiple words)\n",
    "                        continue\n",
    "                    if word not in word_candidates or prob > word_candidates[word]:\n",
    "                        word_candidates[word] = prob\n",
    "\n",
    "            # Sort candidates by probability\n",
    "            sorted_candidates = sorted(\n",
    "                word_candidates.items(), key=lambda x: x[1], reverse=True\n",
    "            )\n",
    "            predictions.append({word: prob for word, prob in sorted_candidates[:topk]})\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def generate_cloze(\n",
    "        self,\n",
    "        summary_text: str,\n",
    "        page_text: str = \"\",\n",
    "        num_blanks: int = 10,\n",
    "    ) -> tuple[str, list[str], list[dict[str, float]]]:\n",
    "        \"\"\"Generate a cloze text from summary using page for context\n",
    "\n",
    "        Args:\n",
    "            page_text: The full page text\n",
    "            summary_text: The summary text to create gaps in\n",
    "            num_blanks: Number of blanks to create\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (cloze_text, answers, alternates)\n",
    "        \"\"\"\n",
    "        # Process both texts\n",
    "        page_doc = self.nlp(page_text)\n",
    "        summary_doc = self.nlp(summary_text)\n",
    "\n",
    "        # Choose positions to blank in the summary\n",
    "        masked_positions = self.choose_blank_positions(\n",
    "            page_doc, summary_doc, num_blanks\n",
    "        )\n",
    "\n",
    "        # Get the answers (the original words that will be blanked)\n",
    "        answers = [summary_doc[pos].text for pos in masked_positions]\n",
    "\n",
    "        # Replace tokens with mask\n",
    "        summary_tokens = np.array(self._get_leading_ws_tokens(summary_doc))\n",
    "        summary_tokens[masked_positions] = \"[MASK]\"\n",
    "        summary_tokens = summary_tokens.tolist()\n",
    "\n",
    "        # Construct cloze token input for gap predictions\n",
    "        cloze_tokens = self._get_leading_ws_tokens(page_doc) + summary_tokens\n",
    "\n",
    "        # Collect gaps\n",
    "        gaps = []\n",
    "        for tok in summary_doc:\n",
    "            if tok.i in masked_positions:\n",
    "                gaps.append((tok.text, tok.idx, len(tok.text)))\n",
    "\n",
    "        return gaps\n",
    "\n",
    "    def score_cloze_answers(self, text_with_masks: str, top_k: int) -> list[dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Return, for each [MASK], a dict {token -> probability}.\n",
    "        \"\"\"\n",
    "        # normalize top_k \n",
    "        k_norm = _normalize_topk_for_use(top_k)\n",
    "        k = 5000 if k_norm is None else int(k_norm)\n",
    "    \n",
    "        inputs = self.tokenizer(text_with_masks, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        logits = outputs.logits  # [batch, seq, vocab]\n",
    "    \n",
    "        mask_positions = torch.where(inputs[\"input_ids\"][0] == self.tokenizer.mask_token_id)[0]\n",
    "    \n",
    "        results = []\n",
    "        for pos in mask_positions:\n",
    "            vec = logits[0, pos.item()]            # [vocab]\n",
    "            probs = torch.softmax(vec, dim=-1)\n",
    "            top_probs, top_idx = torch.topk(probs, k)   # <- k is guaranteed int\n",
    "            preds = {}\n",
    "            for p, idx in zip(top_probs.tolist(), top_idx.tolist()):\n",
    "                token = self.tokenizer.decode([idx]).strip()\n",
    "                preds[token] = p\n",
    "            results.append(preds)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e76c535a-accd-44d7-97af-52dcbe35499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_topk_for_use(x):\n",
    "    \"\"\"Return an int topk or None (== unlimited). Accepts int/float/NaN/None/'unlimited'.\"\"\"\n",
    "    if x is None: \n",
    "        return None\n",
    "    if isinstance(x, str) and x.strip().lower() == \"unlimited\":\n",
    "        return None\n",
    "    try:\n",
    "        # treat NaN like unlimited\n",
    "        if isinstance(x, float) and np.isnan(x):\n",
    "            return None\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return None  # safest fallback: unlimited\n",
    "\n",
    "def _display_topk(x):\n",
    "    \"\"\"Return a display value for topk: int or 'unlimited'.\"\"\"\n",
    "    k = _normalize_topk_for_use(x)\n",
    "    return \"unlimited\" if k is None else int(k)\n",
    "\n",
    "def mask_by_char_spans(text: str, spans: list[tuple[int, int]]) -> str:\n",
    "    \"\"\"Replace text at gapped locations with [MASK] using (start, end) tuples\"\"\"\n",
    "    for start, end in sorted(spans, reverse=True):\n",
    "        text = text[:start] + \"[MASK]\" + text[end:]\n",
    "    return text\n",
    "\n",
    "def _extract_from_contextuality_plus(row):\n",
    "    \"\"\"\n",
    "    extract all relevant information from dataframe\n",
    "    Return:\n",
    "      summary_text : str\n",
    "      gap_spans    : list[(start, end)]\n",
    "      originals    : list[str]\n",
    "    \"\"\"\n",
    "    cp = row.contextuality_plus\n",
    "    summary_text = cp.get(\"text\", row.summary)\n",
    "    gap_spans, originals = [], []\n",
    "    for word, start, length in cp.get(\"gaps\", []):\n",
    "        originals.append(word)\n",
    "        gap_spans.append((start, start + length))\n",
    "    return summary_text, gap_spans, originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ed305c-cb3f-4f62-ad0b-ca6b0d48dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_accepted_answers(\n",
    "    gapper,\n",
    "    page_text: str,\n",
    "    row,\n",
    "    min_probability: float = 0.05,\n",
    "    topk: int | None = None,\n",
    "):\n",
    "    summary_text, gap_spans, originals = _extract_from_contextuality_plus(row)\n",
    "    masked_summary = mask_by_char_spans(summary_text, gap_spans)\n",
    "\n",
    "    page_str = \"\".join(gapper._get_leading_ws_tokens(gapper.nlp(page_text)))\n",
    "    full_context = page_str + \"\\n\\n\" + masked_summary\n",
    "\n",
    "    k_norm = _normalize_topk_for_use(topk)\n",
    "    k_arg = 5000 if k_norm is None else int(k_norm)\n",
    "\n",
    "    preds_per_gap = gapper.score_cloze_answers(full_context, top_k=k_arg)\n",
    "\n",
    "    accepted = []\n",
    "    for i, pred_dict in enumerate(preds_per_gap):\n",
    "        keep = set()\n",
    "        for w, p in pred_dict.items():\n",
    "            w2 = w.strip()\n",
    "            if w2 and \" \" not in w2 and w2.isalpha() and p >= min_probability:\n",
    "                keep.add(w2.lower())\n",
    "        if i < len(originals):\n",
    "            keep.add(originals[i].strip().lower())\n",
    "        accepted.append(keep)\n",
    "\n",
    "    return accepted, originals\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate accuracy of annotations given new acceptable answers\n",
    "def rescore_annotations(\n",
    "    df,\n",
    "    gapper,\n",
    "    min_probability: float = 0.05,\n",
    "    topk: int | None = None,\n",
    "):\n",
    "    rows = []\n",
    "    for row in tqdm(df.itertuples(), total=len(df), desc=\"Rescoring\"):\n",
    "        accepted, originals = generate_accepted_answers(\n",
    "            gapper=gapper,\n",
    "            page_text=row.text,\n",
    "            row=row,\n",
    "            min_probability=min_probability,\n",
    "            topk=topk,\n",
    "        )\n",
    "\n",
    "        # Use human answers\n",
    "        human = [answer.strip().lower() for answer in row.answers]\n",
    "\n",
    "        flags = []\n",
    "        for i, ans in enumerate(human):\n",
    "            okset = accepted[i] if i < len(accepted) else set()\n",
    "            if not okset and i < len(originals):  # safety fallback\n",
    "                okset = {originals[i].strip().lower()}\n",
    "            flags.append(ans in okset)\n",
    "\n",
    "        percent = 100.0 * (sum(flags) / max(1, len(flags)))\n",
    "        rows.append(\n",
    "            {\n",
    "                \"accepted_answers\": accepted,\n",
    "                \"human_correctness\": flags,\n",
    "                \"percent_correct_alt\": percent,\n",
    "                \"alt_counts\": [len(s) for s in accepted],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    extra = pd.DataFrame(rows, index=df.index)\n",
    "    return pd.concat([df.copy(), extra], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e011595b-5546-4f7a-9621-5d97a9b20fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gapper = ContextualityGapper(model_name=\"answerdotai/ModernBERT-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c89ec7b5-243c-4ddc-bece-59064296d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "#      ANALYZE HUMAN AGREEMENT PATTERNS\n",
    "# ============================================\n",
    "def analyze_human_agreement(df):\n",
    "    \"\"\"\n",
    "    Find cases where multiple humans gave the same *incorrect* answer\n",
    "    for the same passage and the same gap index.\n",
    "    Returns: (counts_df, common_df)\n",
    "    \"\"\"\n",
    "    recs = []\n",
    "    for _, row in df.iterrows():\n",
    "        pid   = row[\"passageId\"]\n",
    "        anns  = row[\"answers\"] # human answers\n",
    "        golds = row[\"correctAnswers\"]\n",
    "        for i, (ann, gold) in enumerate(zip(anns, golds)):\n",
    "            ann  = ann.strip().lower()\n",
    "            gold = gold.strip().lower()\n",
    "            if ann != gold:\n",
    "                recs.append({\"passageId\": pid, \"gap_idx\": i, \"human_answer\": ann})\n",
    "\n",
    "    if not recs:\n",
    "        print(\"No wrong answers found.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    tmp = pd.DataFrame(recs)\n",
    "    counts = (\n",
    "        tmp.value_counts([\"passageId\", \"gap_idx\", \"human_answer\"])\n",
    "        .reset_index(name=\"n\")\n",
    "        .sort_values(\"n\", ascending=False)\n",
    "    )\n",
    "    common = counts[counts[\"n\"] > 1]\n",
    "\n",
    "    print(f\"Found {len(common)} (passageId, gap_idx) cases with agreement on the same wrong answer.\")\n",
    "    if not common.empty:\n",
    "        print(\"\\nTop 10:\")\n",
    "        print(common.head(10).to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\nNo per-gap agreements detected. This usually means one annotator per passage, or all wrong answers are unique.\")\n",
    "\n",
    "    return counts, common\n",
    "\n",
    "\n",
    "def _prop_repeated_alts_captured(df_rescored: pd.DataFrame, common_df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Percentage of (passageId, gap_idx, human_answer) 'common wrong answers'\n",
    "    that are captured by the accepted sets under current parameters.\n",
    "    Returns a percentage [0..100].\n",
    "    \"\"\"\n",
    "    if common_df is None or common_df.empty:\n",
    "        return 0.0\n",
    "\n",
    "    rescored_by_pid = df_rescored.set_index(\"passageId\", drop=False)\n",
    "\n",
    "    matched = 0\n",
    "    total = 0\n",
    "    for _, rec in common_df.iterrows():\n",
    "        pid = rec[\"passageId\"]\n",
    "        gap = int(rec[\"gap_idx\"])\n",
    "        ans = str(rec[\"human_answer\"]).strip().lower()\n",
    "\n",
    "        if pid not in rescored_by_pid.index:\n",
    "            continue\n",
    "\n",
    "        # Handle possible duplicate rows per passageId\n",
    "        obj = rescored_by_pid.loc[pid]\n",
    "        candidate_rows = (\n",
    "            obj.to_dict(orient=\"records\") if isinstance(obj, pd.DataFrame)\n",
    "            else [obj.to_dict()]\n",
    "        )\n",
    "\n",
    "        found = False\n",
    "        for r in candidate_rows:\n",
    "            acc = r.get(\"accepted_answers\", None)\n",
    "            if not isinstance(acc, (list, tuple)):\n",
    "                continue\n",
    "            if 0 <= gap < len(acc) and ans in acc[gap]:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        total += 1\n",
    "        if found:\n",
    "            matched += 1\n",
    "\n",
    "    return 100.0 * matched / max(1, total)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "#            PARAMETER GRID SEARCH\n",
    "# ============================================\n",
    "\n",
    "\n",
    "def test_parameters(df, gapper, min_prob_values, topk_values=None, common_df=None):\n",
    "    results = []\n",
    "\n",
    "    if topk_values is None:\n",
    "        topk_values = [10_000]  # Effectively unlimited\n",
    "\n",
    "    total_tests = len(min_prob_values) * len(topk_values)\n",
    "    pbar = tqdm(total=total_tests, desc=\"Testing parameters\")\n",
    "\n",
    "    for min_prob in min_prob_values:\n",
    "        for topk in topk_values:\n",
    "            k_use = _normalize_topk_for_use(topk)\n",
    "\n",
    "            df_rescored = rescore_annotations(\n",
    "                df.copy(),\n",
    "                gapper,\n",
    "                min_probability=min_prob,\n",
    "                topk=k_use,\n",
    "            )\n",
    "\n",
    "            # --- ADDED: compute \"proportion of gaps with 1..5 alternatives\" as a dataset-wide proportion\n",
    "            alt_counts_flat = [c for row in df_rescored[\"alt_counts\"] for c in row]\n",
    "            prop_alts_1_5 = 100.0 * sum(1 <= c <= 5 for c in alt_counts_flat) / max(1, len(alt_counts_flat))\n",
    "\n",
    "            # --- ADDED: compute \"proportion of repeated alt answers captured\"\n",
    "            prop_repeats_captured = _prop_repeated_alts_captured(df_rescored, common_df)\n",
    "\n",
    "            metrics = {\n",
    "                \"min_prob\": min_prob,\n",
    "                \"topk\": _display_topk(topk),\n",
    "                \"mean_accuracy\": df_rescored[\"percent_correct_alt\"].mean(),\n",
    "                \"median_accuracy\": df_rescored[\"percent_correct_alt\"].median(),\n",
    "                \"std_accuracy\": df_rescored[\"percent_correct_alt\"].std(),\n",
    "                \"mean_alternatives\": df_rescored[\"alt_counts\"].apply(lambda x: np.mean(x)).mean(),\n",
    "                \"median_alternatives\": df_rescored[\"alt_counts\"].apply(lambda x: np.median(x)).median(),\n",
    "                \"max_alternatives\": df_rescored[\"alt_counts\"].apply(lambda x: np.max(x)).max(),\n",
    "\n",
    "                # OLD row-level metric kept for reference, but no longer used in score:\n",
    "                \"gaps_with_1_5_alts_rows_all_ok\": (\n",
    "                    sum(df_rescored[\"alt_counts\"].apply(lambda x: all(1 <= c <= 5 for c in x)))\n",
    "                    / len(df_rescored) * 100\n",
    "                ),\n",
    "\n",
    "                # NEW METRICS:\n",
    "                \"prop_alts_1_5\": prop_alts_1_5,\n",
    "                \"prop_repeated_alt_answers_captured\": prop_repeats_captured,\n",
    "            }\n",
    "\n",
    "            # --- NEW SCORE: equal weight across the three criteria (all already in % units)\n",
    "            metrics[\"score\"] = (\n",
    "                metrics[\"mean_accuracy\"]\n",
    "                + metrics[\"prop_alts_1_5\"]\n",
    "                + metrics[\"prop_repeated_alt_answers_captured\"]\n",
    "            )\n",
    "\n",
    "            results.append(metrics)\n",
    "            pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================\n",
    "#                 BEST PARAMS\n",
    "# ============================================\n",
    "\n",
    "\n",
    "def analyze_best_parameters(df, gapper, min_prob, topk, common_df):\n",
    "    \"\"\"\n",
    "    Analysis of a specific parameter combo.\n",
    "    common_df is the DataFrame returned by analyze_human_agreement(...)[1]\n",
    "\n",
    "    FIXED: Properly handles NaN/None topk display, KeyError, and index out-of-bounds issues.\n",
    "    \"\"\"\n",
    "    # Re-run rescoring with given parameters\n",
    "    df_rescored = rescore_annotations(\n",
    "        df.copy(), gapper, min_probability=min_prob, topk=topk\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"DETAILED ANALYSIS: min_prob={min_prob}, topk={_display_topk(topk)}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # === Overall Stats ===\n",
    "    print(f\"\\nOverall Performance:\")\n",
    "    print(f\"  Mean accuracy: {df_rescored['percent_correct_alt'].mean():.1f}%\")\n",
    "    print(f\"  Median accuracy: {df_rescored['percent_correct_alt'].median():.1f}%\")\n",
    "    print(f\"  Std deviation: {df_rescored['percent_correct_alt'].std():.1f}%\")\n",
    "\n",
    "    # === Alternative Answer Counts ===\n",
    "    alt_counts_flat = [c for row in df_rescored[\"alt_counts\"] for c in row]\n",
    "    print(f\"\\nAlternative Answers per Gap:\")\n",
    "    print(f\"  Mean: {np.mean(alt_counts_flat):.1f}\")\n",
    "    print(f\"  Median: {np.median(alt_counts_flat):.0f}\")\n",
    "    print(f\"  Max: {np.max(alt_counts_flat)}\")\n",
    "    print(f\"  % gaps with 1–5 alternatives: \"\n",
    "          f\"{sum(1 <= c <= 5 for c in alt_counts_flat) / len(alt_counts_flat) * 100:.1f}%\")\n",
    "\n",
    "    # === Check how many 'common wrong' answers are accepted ===\n",
    "    accepted_mistakes = 0\n",
    "    total_mistakes = len(common_df)\n",
    "    errors_encountered = 0\n",
    "\n",
    "    if total_mistakes:\n",
    "        rescored_by_pid = df_rescored.set_index(\"passageId\", drop=False)\n",
    "\n",
    "        for _, rec in common_df.iterrows():\n",
    "            pid = rec[\"passageId\"]\n",
    "            gap = int(rec[\"gap_idx\"])\n",
    "            ans = str(rec[\"human_answer\"]).strip().lower()\n",
    "\n",
    "            if pid not in rescored_by_pid.index:\n",
    "                continue\n",
    "\n",
    "            obj = rescored_by_pid.loc[pid]\n",
    "            candidate_rows = (\n",
    "                obj.to_dict(orient=\"records\") if isinstance(obj, pd.DataFrame)\n",
    "                else [obj.to_dict()]\n",
    "            )\n",
    "\n",
    "            matched = False\n",
    "            for r in candidate_rows:\n",
    "                acc = r.get(\"accepted_answers\", None)\n",
    "                if not isinstance(acc, (list, tuple)):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    if gap < len(acc) and ans in acc[gap]:\n",
    "                        matched = True\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    print(f\"KeyError in analyze_best_parameters. Attempting to access index {gap} of:\\n\", acc)\n",
    "                    errors_encountered += 1\n",
    "                except Exception as e:\n",
    "                    # General catch\n",
    "                    print(f\"[warn] issue at pid={pid}, gap={gap}: {e}\")\n",
    "                    errors_encountered += 1\n",
    "\n",
    "            if matched:\n",
    "                accepted_mistakes += 1\n",
    "\n",
    "    # === Summary Output ===\n",
    "    print(f\"\\nCommon Human Agreements (per passage+gap):\")\n",
    "    if total_mistakes:\n",
    "        print(f\"  Accepting {accepted_mistakes}/{total_mistakes} agreed-on 'incorrect' answers\")\n",
    "        if errors_encountered > 0:\n",
    "            print(f\"  Note: {errors_encountered} entries had mismatched gap indices or missing data\")\n",
    "    else:\n",
    "        print(\"  (None found in this dataset)\")\n",
    "\n",
    "    return df_rescored\n",
    "\n",
    "def _sentence_with_gap(summary_text: str, gap_span: tuple[int, int], pad: int = 0) -> str:\n",
    "    \"\"\"\n",
    "    Return the sentence containing the gap, with the gap shown as ‹…›.\n",
    "    Falls back to a local window if punctuation is missing.\n",
    "    \"\"\"\n",
    "    start, end = gap_span\n",
    "    n = len(summary_text)\n",
    "\n",
    "    # find sentence bounds (simple punctuation heuristics)\n",
    "    left = max(summary_text.rfind('.', 0, start),\n",
    "               summary_text.rfind('?', 0, start),\n",
    "               summary_text.rfind('!', 0, start))\n",
    "    right_period = summary_text.find('.', end)\n",
    "    right_q = summary_text.find('?', end)\n",
    "    right_ex = summary_text.find('!', end)\n",
    "    rights = [x for x in [right_period, right_q, right_ex] if x != -1]\n",
    "    right = min(rights) if rights else -1\n",
    "\n",
    "    s = left + 1 if left != -1 else max(0, start - 120)\n",
    "    e = right + 1 if right != -1 else min(n, end + 120)\n",
    "\n",
    "    s = max(0, s - pad)\n",
    "    e = min(n, e + pad)\n",
    "\n",
    "    pre = summary_text[s:start]\n",
    "    gap = summary_text[start:end]\n",
    "    post = summary_text[end:e]\n",
    "    return pre + \"‹\" + gap + \"›\" + post\n",
    "\n",
    "import re\n",
    "\n",
    "def review_repeated_answers_with_sentence(df_rescored: pd.DataFrame,\n",
    "                                          common_df: pd.DataFrame,\n",
    "                                          acc_preview: int = 6,\n",
    "                                          max_sentence_len: int = 220) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a tidy audit table + one sentence string where the ORIGINAL gold word is highlighted:  ‹word›\n",
    "    Columns:\n",
    "      passageId, gap_idx, gold_original, repeated_human, accepted_now,\n",
    "      accepted_set_size, accepted_set_preview, sentence\n",
    "    \"\"\"\n",
    "    cols = [\"passageId\",\"gap_idx\",\"gold_original\",\"repeated_human\",\n",
    "            \"accepted_now\",\"accepted_set_size\",\"accepted_set_preview\",\"sentence\"]\n",
    "    if common_df is None or common_df.empty:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    rows_out = []\n",
    "    by_pid = df_rescored.set_index(\"passageId\", drop=False)\n",
    "\n",
    "    for _, rec in common_df.iterrows():\n",
    "        pid = rec[\"passageId\"]\n",
    "        gap = int(rec[\"gap_idx\"])\n",
    "        human_raw = str(rec[\"human_answer\"]).strip().lower()\n",
    "\n",
    "        if pid not in by_pid.index:\n",
    "            continue\n",
    "\n",
    "        obj = by_pid.loc[pid]\n",
    "\n",
    "        # iterate as Series (not dict) so _extract_from_contextuality_plus works\n",
    "        if isinstance(obj, pd.DataFrame):\n",
    "            series_iter = (row for _, row in obj.iterrows())\n",
    "        else:  # already a Series\n",
    "            series_iter = [obj]\n",
    "\n",
    "        accepted_now = False\n",
    "        acc_set = set()\n",
    "        gold_original = \"\"\n",
    "        sentence = \"\"\n",
    "\n",
    "        for r in series_iter:\n",
    "            # accepted set for this gap\n",
    "            acc = r.get(\"accepted_answers\", [])\n",
    "            if 0 <= gap < len(acc):\n",
    "                acc_set = acc[gap]\n",
    "                accepted_now = (human_raw in acc_set)\n",
    "\n",
    "            # pull summary text + spans + originals from contextuality_plus\n",
    "            try:\n",
    "                summary_text, gap_spans, originals = _extract_from_contextuality_plus(r)\n",
    "            except Exception:\n",
    "                summary_text, gap_spans, originals = r.get(\"summary\",\"\"), [], []\n",
    "\n",
    "            if 0 <= gap < len(originals):\n",
    "                gold_original = (originals[gap] or \"\").strip()\n",
    "\n",
    "            if summary_text and 0 <= gap < len(gap_spans):\n",
    "                s = _sentence_with_gap(summary_text, gap_spans[gap])  # shows ‹gold›\n",
    "                s = re.sub(r\"\\s+\", \" \", s).strip()                     # single-line\n",
    "                if len(s) > max_sentence_len:\n",
    "                    s = s[:max_sentence_len-3] + \"...\"\n",
    "                sentence = s\n",
    "\n",
    "            # first usable row is enough\n",
    "            break\n",
    "\n",
    "        rows_out.append({\n",
    "            \"passageId\": pid,\n",
    "            \"gap_idx\": gap,\n",
    "            \"gold_original\": gold_original,\n",
    "            \"repeated_human\": human_raw,\n",
    "            \"accepted_now\": bool(accepted_now),\n",
    "            \"accepted_set_size\": len(acc_set) if isinstance(acc_set, (set, list, tuple)) else 0,\n",
    "            \"accepted_set_preview\": \", \".join(sorted(list(acc_set))[:acc_preview]) if isinstance(acc_set, (set, list, tuple)) else \"\",\n",
    "            \"sentence\": sentence\n",
    "        })\n",
    "\n",
    "    df_out = pd.DataFrame(rows_out).sort_values(\n",
    "        [\"accepted_now\",\"accepted_set_size\",\"passageId\",\"gap_idx\"],\n",
    "        ascending=[True, True, True, True]\n",
    "    )\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f20ec33-5f78-455f-bd56-a26b8ac6e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_testing(df, gapper):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PARAMETER OPTIMIZATION FOR CLOZE SCORING\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"\\nSTEP 1: Analyzing Human Agreement Patterns_____\")\n",
    "    counts_df, common_df = analyze_human_agreement(df)\n",
    "\n",
    "    print(\"\\nSTEP 2: Testing Parameter Combinations_____\")\n",
    "    min_prob_values = [0.002, 0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.07, 0.10, 0.15, 0.20]\n",
    "    topk_values = [5, 10, 20, 50, 100, None]\n",
    "\n",
    "\n",
    "    # --- CHANGED: pass common_df\n",
    "    results_df = test_parameters(df, gapper, min_prob_values, topk_values, common_df=common_df)\n",
    "\n",
    "    print(\"\\nSTEP 3: Finding Optimal Parameters_____\")\n",
    "\n",
    "    # --- REMOVED old score formulas entirely; score is built inside test_parameters now.\n",
    "\n",
    "    best_params = results_df.nlargest(5, \"score\")\n",
    "    print(\"\\nTOP 5 PARAMETER COMBINATIONS:\")\n",
    "    print(\n",
    "        best_params[\n",
    "            [\n",
    "                \"min_prob\",\n",
    "                \"topk\",\n",
    "                \"mean_accuracy\",\n",
    "                \"prop_alts_1_5\",\n",
    "                \"prop_repeated_alt_answers_captured\",\n",
    "                \"score\",\n",
    "            ]\n",
    "        ].to_string(index=False)\n",
    "    )\n",
    "\n",
    "    best_row = best_params.iloc[0]\n",
    "    best_min_prob = float(best_row[\"min_prob\"])\n",
    "    best_topk = _normalize_topk_for_use(best_row[\"topk\"])\n",
    "\n",
    "    print(\"\\nSTEP 4: Best Parameters______\")\n",
    "    df_best = analyze_best_parameters(df, gapper, best_min_prob, best_topk, common_df)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINAL RECOMMENDATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nRECOMMENDED PARAMETERS:\")\n",
    "    print(f\"  min_probability = {best_min_prob}\")\n",
    "    print(f\"  topk = {_display_topk(best_topk)}\")\n",
    "    print(f\"\\nExpected Performance:\")\n",
    "    print(f\"  Mean human accuracy: {best_row['mean_accuracy']:.1f}%\")\n",
    "    print(f\"  Proportion gaps with 1–5 alternatives: {best_row['prop_alts_1_5']:.1f}%\")\n",
    "    print(f\"  Repeated human alternatives captured: {best_row['prop_repeated_alt_answers_captured']:.1f}%\")\n",
    "\n",
    "    return results_df, df_best, best_min_prob, best_topk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c65a4a19-20bb-4e5a-b874-9966dbeed7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 (passageId, gap_idx) cases with agreement on the same wrong answer.\n",
      "\n",
      "Top 10:\n",
      " passageId  gap_idx human_answer  n\n",
      "         5        5  experiences  5\n",
      "         5        2        prove  4\n",
      "         1        7  advancement  3\n",
      "         3        3    examining  2\n",
      "         6        3     variable  2\n",
      "         1        0    unfounded  2\n",
      "         1        5       debunk  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b822d60fb64e0eabc71c4e0186248c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DETAILED ANALYSIS: min_prob=0.07, topk=unlimited\n",
      "============================================================\n",
      "\n",
      "Overall Performance:\n",
      "  Mean accuracy: 77.5%\n",
      "  Median accuracy: 77.8%\n",
      "  Std deviation: 15.6%\n",
      "\n",
      "Alternative Answers per Gap:\n",
      "  Mean: 1.9\n",
      "  Median: 1\n",
      "  Max: 5\n",
      "  % gaps with 1–5 alternatives: 100.0%\n",
      "\n",
      "Common Human Agreements (per passage+gap):\n",
      "  Accepting 2/7 agreed-on 'incorrect' answers\n",
      "\n",
      "REVIEW repeated answers (with sentence):\n",
      " passageId  gap_idx gold_original repeated_human  accepted_now  accepted_set_size                                   accepted_set_preview                                                                                                                                                                    sentence\n",
      "         1        0     intuitive      unfounded         False                  1                                              intuitive                                                                      However, scientific research frequently contradicts these ‹_________› beliefs, revealing inaccuracies.\n",
      "         6        3      entities       variable         False                  1                                               entities                   Operational definitions transform ________ constructs, such as depression, into measurable ‹________›, often using established methods in the literature.\n",
      "         1        5     challenge         debunk         False                  2                                    challenge, overcome                                                               Psychologists emphasize __________ and the pursuit of empirical evidence to ‹_________› these misconceptions.\n",
      "         5        2         shows          prove         False                  2                                        shows, suggests                                           Authority ________ accepting ideas from figures like parents or the media, though history ‹_____› such sources can be misleading.\n",
      "         5        5   limitations    experiences         False                  2                                    biases, limitations                                                                       Empiricism is _____ on observation and experience, yet can be deceptive due to sensory ‹___________›.\n",
      "         1        7   exploration    advancement          True                  2                               advancement, exploration                                                       Additionally, they embrace ___________, welcoming unanswered questions as opportunities for scientific ‹___________›.\n",
      "         3        3     exploring      examining          True                  5 asking, examining, exploring, investigating, measuring Alternatively, one can generate questions by _______________ a behavior or characteristic as a variable and ‹_________› its frequency or relationship with other variables.\n"
     ]
    }
   ],
   "source": [
    "counts_df, common_df = analyze_human_agreement(df)\n",
    "df_best = analyze_best_parameters(df, gapper, best_min_prob, best_topk, common_df)\n",
    "\n",
    "review_sent = review_repeated_answers_with_sentence(df_best, common_df, acc_preview=6, max_sentence_len=220)\n",
    "print(\"\\nREVIEW repeated answers (with sentence):\")\n",
    "print(review_sent.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc18f925-6bb7-4d40-b39d-618798c5c0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PARAMETER OPTIMIZATION FOR CLOZE SCORING\n",
      "============================================================\n",
      "\n",
      "STEP 1: Analyzing Human Agreement Patterns_____\n",
      "Found 7 (passageId, gap_idx) cases with agreement on the same wrong answer.\n",
      "\n",
      "Top 10:\n",
      " passageId  gap_idx human_answer  n\n",
      "         5        5  experiences  5\n",
      "         5        2        prove  4\n",
      "         1        7  advancement  3\n",
      "         3        3    examining  2\n",
      "         6        3     variable  2\n",
      "         1        0    unfounded  2\n",
      "         1        5       debunk  2\n",
      "\n",
      "STEP 2: Testing Parameter Combinations_____\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5107edf1bacc41929d1b89a4396e72d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing parameters:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb8bf0f5d60413e8d0ee25e03dc1dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4aaff1ba5c4e65b13fa14035fe3191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f295e327ab4b999f507a35710d8702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52edfde0e354e0eaa2d8491159b42be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989eda7263614344ad36cfc2ed392b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20afb30fd7c84f59bb9a68928cbbe155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90341b9ab68145a188b5bbda8bd1351f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20f5def0fb14fb0b4e755367735bde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac4f38fc2e14d03840e29120bb05bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d75d5a3b3a04a35abf9628564b7dbb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79120f9f21eb474eb9cbaed8ce2b5566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f8df8a2f1542b287c32b453171c3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03350e265aa45c98664bc0ab78a38a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9790e15a398c42609f756cfc6171f8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5578c4ba0f3840449e70964d30fe6305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385f75fbe0a34fa398f6a68cbd74935d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8651f742288f461682f5314edb4d8bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f36f2bfb04f4e3da13ae66dcb9bbd20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da63225a37b42bd8d1cf436d41cc5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a0e79063cb4dadadf837a5713b27b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e803925fbbdd4f78ac2f7e622c3b1da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4fcc058d3e4540adf2aa220773d4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f318f99b20404b89241c8a88a84e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63276318d22a46bcbed43f2dffd8a0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fdee803e154d2b87606237b60a95fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6171f561ee2541589ff3a6a55efae76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e8ac90ba354f0ea58941b52172ba5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659a92b57a8d49a5abb212fde36a652e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4edc691ae14ad094dc90d0501e5f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1893e207d64a4db19b8d0d35d1f8615f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5786e6ff38aa41f5a5c859a98675a3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4d586c89314483a0c99f8a4d1fd279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72f78b4082a44a187779dd6714038d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64aa64eaca24137a1fc07e599e2da40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445b2947fee04bea908da865412ad04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f854b9be902472f8233bec63b7782e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75f2dfe7b934444b6bece726914c40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d875d286a26476ea76abc18b3c63abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e82377c613489a974b68eb5a68bcf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13c890c490d4b6484b70abc67d75fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651b38c1ae614c30968189c818bf3138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2239d26f0cff476b950ee114d1574488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09449287dc8e48e7bf854c28399796c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d87eacce3143b593404594a3fd4fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0bcb31a7734b809119f60e5e1ebefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de84be712334267840e2805e83c8777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895fd4a9015b4f3b8c5b1a201f430f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1187f0341e4bb0b5f4cfe3605c40d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d66f84b5c584180a576f591e2f9dcef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dabb5fd5c7a45fabcb54187c7793bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a38968f63c2438f99037ae16e66819d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a289054d310447aa997b10506baaabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9a0673655544ad861e877e72dd4b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7e067585b34955a861bbac1bbbb0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7771e61e22f54eef86b024b4eda6d51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949b7941f0e6479493c1191046698f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b01877b1fd14f31812de0c79a633374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbef36910de48d9b7689b1682c14af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc925fb70c224977ac8c4823ad16931e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7493a6e66d5d43f186e2f86ac9a83fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cc85a45a27469fb8294cd9446fe2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae06c165e8854ac8b5874fb8acb02ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2c2bfccf2540da9620d34ad7ea500e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f42f51f50b4992b7abd348339b0423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135bb4c4ac3c4ba5832441a5bbd8c13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654a1126ef1f42fbaa8e4217ef6b6e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 3: Finding Optimal Parameters_____\n",
      "\n",
      "TOP 5 PARAMETER COMBINATIONS:\n",
      " min_prob      topk  mean_accuracy  prop_alts_1_5  prop_repeated_alt_answers_captured      score\n",
      "     0.07 unlimited      77.500000     100.000000                           28.571429 206.071429\n",
      "     0.05 unlimited      77.934783      97.584541                           28.571429 204.090752\n",
      "     0.07         5      77.500000      97.101449                           28.571429 203.172878\n",
      "     0.07        10      77.500000      97.101449                           28.571429 203.172878\n",
      "     0.07        20      77.500000      97.101449                           28.571429 203.172878\n",
      "\n",
      "STEP 4: Best Parameters______\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e564edf72c64702a4168d4ea379f1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DETAILED ANALYSIS: min_prob=0.07, topk=unlimited\n",
      "============================================================\n",
      "\n",
      "Overall Performance:\n",
      "  Mean accuracy: 77.5%\n",
      "  Median accuracy: 77.8%\n",
      "  Std deviation: 15.6%\n",
      "\n",
      "Alternative Answers per Gap:\n",
      "  Mean: 1.9\n",
      "  Median: 1\n",
      "  Max: 5\n",
      "  % gaps with 1–5 alternatives: 100.0%\n",
      "\n",
      "Common Human Agreements (per passage+gap):\n",
      "  Accepting 2/7 agreed-on 'incorrect' answers\n",
      "\n",
      "============================================================\n",
      "FINAL RECOMMENDATIONS\n",
      "============================================================\n",
      "\n",
      "RECOMMENDED PARAMETERS:\n",
      "  min_probability = 0.07\n",
      "  topk = unlimited\n",
      "\n",
      "Expected Performance:\n",
      "  Mean human accuracy: 77.5%\n",
      "  Proportion gaps with 1–5 alternatives: 100.0%\n",
      "  Repeated human alternatives captured: 28.6%\n"
     ]
    }
   ],
   "source": [
    "results_df, df_best, best_min_prob, best_topk = run_testing(df, gapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fbbbd673-574d-4aea-a702-6ff2c9e2a93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3e2f27eb40461f95fcaf57dec9b3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pid=5, gap=5) human_wrong='experiences'  -> accepted? False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f8ae2648754b87b9ec6ac9f54b5b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pid=5, gap=2) human_wrong='prove'  -> accepted? False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6cccbc3e35405dbf9787b449c48a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pid=1, gap=7) human_wrong='advancement'  -> accepted? True\n"
     ]
    }
   ],
   "source": [
    "# Smoke test on a couple of (pid, gap) pairs from common_df\n",
    "test_rows = common_df.head(3).to_dict(orient=\"records\")\n",
    "for rec in test_rows:\n",
    "    pid = int(rec[\"passageId\"])\n",
    "    gap = int(rec[\"gap_idx\"])\n",
    "    ans = str(rec[\"human_answer\"]).strip().lower()\n",
    "\n",
    "    sub = df[df[\"passageId\"] == pid].copy()\n",
    "    resc = rescore_annotations(sub, gapper, min_probability=0.07, topk=None)\n",
    "    matched = False\n",
    "    for r in resc.to_dict(orient=\"records\"):\n",
    "        acc = r.get(\"accepted_answers\", [])\n",
    "        if isinstance(acc, list) and 0 <= gap < len(acc) and ans in acc[gap]:\n",
    "            matched = True\n",
    "            break\n",
    "    print(f\"(pid={pid}, gap={gap}) human_wrong='{ans}'  -> accepted? {matched}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "64e62acd-3958-4c65-b967-34c756484117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3     [unfounded, alleviate, confessions, calorie, s...\n",
      "4     [unfounded, alleviate, confessions, calorie, s...\n",
      "5     [intuitive, alleviate, confessions, calorie, s...\n",
      "6     [intuitive, alleviate, confessions, calorie, s...\n",
      "14    [achieved, researchers, conceptualizing, exami...\n",
      "15    [achieved, researchers, conceptualizing, exami...\n",
      "16    [achieved, researchers, conceptualizing, study...\n",
      "24    [instincts, involves, prove, incorrect, based,...\n",
      "25    [instincts, involves, prove, incorrect, based,...\n",
      "26    [instincts, involves, prove, incorrect, based,...\n",
      "27    [instincts, involves, prove, incorrect, based,...\n",
      "28    [instincts, involves, shows, incorrect, based,...\n",
      "29    [instincts, involves, shows, incorrect, based,...\n",
      "31    [instincts, involves, shows, incorrect, based,...\n",
      "32    [quantitative, chosen, abstract, variable, ide...\n",
      "34    [quantitativ, chosen, abstract, variable, iden...\n",
      "37    [confirming, theory, theories, philosophical, ...\n",
      "40          [intuitive, , confessions, calorie, , , , ]\n",
      "41    [intuitive, alleviate, confessions, calorie, c...\n",
      "45    [cultures, freedom, cultures, cultures, mascul...\n",
      "54    [explain, descriptions, understanding, surveys...\n",
      "60    [intuition, involves, shows, incorrect, based,...\n",
      "66    [determines, qualifications, operators, void, ...\n",
      "Name: answers, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "366c4cd1-0702-43f6-a98c-aa532def3736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PARAMETER OPTIMIZATION FOR CLOZE SCORING\n",
      "============================================================\n",
      "\n",
      "STEP 1: Analyzing Human Agreement Patterns_____\n",
      "Found 41 (passageId, gap_idx) cases with agreement on the same wrong answer.\n",
      "\n",
      "Top 10:\n",
      " passageId  gap_idx  human_answer  n\n",
      "         5        1      sentence  7\n",
      "         5        6        source  6\n",
      "         5        8        source  6\n",
      "         5        2      sentence  6\n",
      "         5        4      sentence  6\n",
      "         5        3      sentence  5\n",
      "         5        5      sentence  5\n",
      "         1        6        source  4\n",
      "         5        7      sentence  4\n",
      "         1        7 unpredictable  4\n",
      "\n",
      "STEP 2: Testing Parameter Combinations_____\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5442d444c2f4476a584d358c0025ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing parameters:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2405112f5814987972d6d8ae9967ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448585cbd38546f39db7bca9e50902e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0dab05b1f84462bfb7bbee30b0f4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80aeff717fa54588ae9778b8a0772a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0360deccd07b4e0ab2b2d7f6ee4b1645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ef1e66ca2647aeb2b2c351506b22c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99586ab6329401299561ab7c478e8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d5acd5217b4d7ea797be3a5690462a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d9b1ee4ad646d4a30012a63493c6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee2f78f087d4f4398f02c04d6551412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7d73fc05144242af387bcffeaa2024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3a83bd9a8942bc8bf8efca299b541c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bee60987b44b8f9a308ae33ce459d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a2bac75d1d4105aa60f35d9020228a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d743f4d79f4afd84aba742e6ec86c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb9ff3dc04d418c8f74f53ca7d80792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75446b5d1a9e4951a2a136df4ffcb157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24990aa38be14851ae6dd51d6294a016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42870a7826a4e4c9e1f2e374ed8ab92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6ae801af0f456cb222d1138e8b2463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0036f77a6b47ef92e5eb7032cb7262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c493972fa834f4eb7dd18a552dc00f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd7f8ea4bb3498cb3ae95be16f8bea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fbbd099f294c02904049312fb87b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df66f6649a54080b186d23e36b5c789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5351ae72db5940718e68285871174753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7335fcc84d854856944bc52c2fc0df38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a132bb684342e99d4c7245dd50415c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496c041af56d4565895eaa33a1ec06ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf6fb7864334137a48a76cd2538a4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f920fcfc5f524d0cb7b69790cb3c8c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d46ff6f4fe4165b9a9d0ef11109080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f587d778b23415a884702ed176e55b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de298abcd704e4c9a74c99ff0cd3de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814a8e23306843268219040c4c077b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bb32618f214c8c8aaaa1a854ee8b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f694efed6d4486eb6adfce92e3b37d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537ab02439cb4379a8c2534a31446547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41340aeac00a4f69ba35398bb4a58fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7898480c3aae4395a24e98f761d87e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 3: Finding Optimal Parameters_____\n",
      "\n",
      "TOP 5 PARAMETER COMBINATIONS:\n",
      " min_prob      topk  mean_accuracy  mean_alternatives  gaps_with_1_5_alts      score\n",
      "     0.07 unlimited            0.0           1.898309               100.0 138.983092\n",
      "     0.10 unlimited            0.0           1.721981               100.0 137.219807\n",
      "     0.15         5            0.0           1.673430               100.0 136.734300\n",
      "     0.15        10            0.0           1.673430               100.0 136.734300\n",
      "     0.15        20            0.0           1.673430               100.0 136.734300\n",
      "\n",
      "STEP 4: Best Parameters______\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14559e5fcbef4409bc80451c67464754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rescoring:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DETAILED ANALYSIS: min_prob=0.07, topk=unlimited\n",
      "============================================================\n",
      "\n",
      "Overall Performance:\n",
      "  Mean accuracy: 0.0%\n",
      "  Median accuracy: 0.0%\n",
      "  Std deviation: 0.0%\n",
      "\n",
      "Alternative Answers per Gap:\n",
      "  Mean: 1.9\n",
      "  Median: 1\n",
      "  Max: 5\n",
      "  % gaps with 1–5 alternatives: 100.0%\n",
      "\n",
      "Common Human Agreements (per passage+gap):\n",
      "  Accepting 0/41 agreed-on 'incorrect' answers\n",
      "\n",
      "============================================================\n",
      "FINAL RECOMMENDATIONS\n",
      "============================================================\n",
      "\n",
      "RECOMMENDED PARAMETERS:\n",
      "  min_probability = 0.07\n",
      "  topk = unlimited\n",
      "\n",
      "Expected Performance:\n",
      "  Mean human accuracy: 0.0%\n",
      "  Mean alternatives per gap: 1.9\n",
      "  Gaps with 1-5 alternatives: 100.0%\n"
     ]
    }
   ],
   "source": [
    "results_df, df_best, best_min_prob, best_topk = run_testing(df, gapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0452f-b63c-43a9-9ec6-bcac096373f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c99a217-34b3-48b6-a5bf-3c31bdc0424e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
