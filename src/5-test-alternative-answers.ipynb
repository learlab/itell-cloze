{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef035409-0d4f-4085-883a-42523e07e2a1",
   "metadata": {},
   "source": [
    "# Lemma Constraint\n",
    "\n",
    "Make sure that gaps are only generated for lemmas that appear in the page text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed39f237-3bfa-40d0-bfbd-b94eacfac367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import seaborn as sns\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8bb68-f6ef-473b-8312-8d8009802517",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Combine the human annotations with the generated cloze exercises and source texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2e34bf-5070-4a1a-bea7-5ddac9e1524b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>page</th>\n",
       "      <th>summary</th>\n",
       "      <th>markdown</th>\n",
       "      <th>text</th>\n",
       "      <th>contextuality</th>\n",
       "      <th>contextuality_plus</th>\n",
       "      <th>keyword</th>\n",
       "      <th>passageId</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>method</th>\n",
       "      <th>score</th>\n",
       "      <th>timeSpent</th>\n",
       "      <th>answers</th>\n",
       "      <th>correctAnswers</th>\n",
       "      <th>annotations</th>\n",
       "      <th>holisticScore</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>annotation_counts</th>\n",
       "      <th>pct_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>research-methods-in-psychology</td>\n",
       "      <td>1-methods-of-knowing</td>\n",
       "      <td>The text discusses various methods of acquirin...</td>\n",
       "      <td>&lt;i-callout variant=\"info\" title=\"Learning Obje...</td>\n",
       "      <td>Learning Objectives\\n\\n1. Describe the 5 metho...</td>\n",
       "      <td>{'text': 'The text discusses various methods o...</td>\n",
       "      <td>{'text': 'The text discusses various methods o...</td>\n",
       "      <td>{'text': 'The text discusses various methods o...</td>\n",
       "      <td>5</td>\n",
       "      <td>fee694i0Gd4YjmNfg4oG</td>\n",
       "      <td>...</td>\n",
       "      <td>contextuality_plus</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>53761.963</td>\n",
       "      <td>[instincts, involves, prove, incorrect, based,...</td>\n",
       "      <td>[instincts, involves, shows, incorrect, based,...</td>\n",
       "      <td>[sentence, sentence, sentence, sentence, sente...</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-05-08T19:05:33.627Z</td>\n",
       "      <td>{'sentence': 7, 'source': 2}</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>research-methods-in-psychology</td>\n",
       "      <td>1-methods-of-knowing</td>\n",
       "      <td>The text discusses various methods of acquirin...</td>\n",
       "      <td>&lt;i-callout variant=\"info\" title=\"Learning Obje...</td>\n",
       "      <td>Learning Objectives\\n\\n1. Describe the 5 metho...</td>\n",
       "      <td>{'text': 'The text discusses various methods o...</td>\n",
       "      <td>{'text': 'The text discusses various methods o...</td>\n",
       "      <td>{'text': 'The text discusses various methods o...</td>\n",
       "      <td>5</td>\n",
       "      <td>WzaDDDH3gMS2wthasHHv</td>\n",
       "      <td>...</td>\n",
       "      <td>contextuality_plus</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>91.867</td>\n",
       "      <td>[instincts, involves, shows, incorrect, based,...</td>\n",
       "      <td>[instincts, involves, shows, incorrect, based,...</td>\n",
       "      <td>[source, sentence, unpredictable, unpredictabl...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-01T20:19:48.729Z</td>\n",
       "      <td>{'source': 1, 'sentence': 2, 'unpredictable': 6}</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            volume                  page  \\\n",
       "26  research-methods-in-psychology  1-methods-of-knowing   \n",
       "31  research-methods-in-psychology  1-methods-of-knowing   \n",
       "\n",
       "                                              summary  \\\n",
       "26  The text discusses various methods of acquirin...   \n",
       "31  The text discusses various methods of acquirin...   \n",
       "\n",
       "                                             markdown  \\\n",
       "26  <i-callout variant=\"info\" title=\"Learning Obje...   \n",
       "31  <i-callout variant=\"info\" title=\"Learning Obje...   \n",
       "\n",
       "                                                 text  \\\n",
       "26  Learning Objectives\\n\\n1. Describe the 5 metho...   \n",
       "31  Learning Objectives\\n\\n1. Describe the 5 metho...   \n",
       "\n",
       "                                        contextuality  \\\n",
       "26  {'text': 'The text discusses various methods o...   \n",
       "31  {'text': 'The text discusses various methods o...   \n",
       "\n",
       "                                   contextuality_plus  \\\n",
       "26  {'text': 'The text discusses various methods o...   \n",
       "31  {'text': 'The text discusses various methods o...   \n",
       "\n",
       "                                              keyword  passageId  \\\n",
       "26  {'text': 'The text discusses various methods o...          5   \n",
       "31  {'text': 'The text discusses various methods o...          5   \n",
       "\n",
       "                      id  ...              method      score  timeSpent  \\\n",
       "26  fee694i0Gd4YjmNfg4oG  ...  contextuality_plus  77.777778  53761.963   \n",
       "31  WzaDDDH3gMS2wthasHHv  ...  contextuality_plus  77.777778     91.867   \n",
       "\n",
       "                                              answers  \\\n",
       "26  [instincts, involves, prove, incorrect, based,...   \n",
       "31  [instincts, involves, shows, incorrect, based,...   \n",
       "\n",
       "                                       correctAnswers  \\\n",
       "26  [instincts, involves, shows, incorrect, based,...   \n",
       "31  [instincts, involves, shows, incorrect, based,...   \n",
       "\n",
       "                                          annotations holisticScore  \\\n",
       "26  [sentence, sentence, sentence, sentence, sente...             4   \n",
       "31  [source, sentence, unpredictable, unpredictabl...             1   \n",
       "\n",
       "                   timestamp  \\\n",
       "26  2025-05-08T19:05:33.627Z   \n",
       "31  2025-06-01T20:19:48.729Z   \n",
       "\n",
       "                                   annotation_counts pct_correct  \n",
       "26                      {'sentence': 7, 'source': 2}   77.777778  \n",
       "31  {'source': 1, 'sentence': 2, 'unpredictable': 6}   77.777778  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df = (\n",
    "    pd.read_csv(\"../data/testResults_from_2025-05-07.csv\")\n",
    "    # Convert dictionaries to lists\n",
    "    .assign(\n",
    "        answers=lambda x: x[\"answers\"].apply(\n",
    "            lambda row: list(json.loads(row).values())\n",
    "        ),\n",
    "        correctAnswers=lambda x: x[\"correctAnswers\"].apply(\n",
    "            lambda row: list(json.loads(row).values())\n",
    "        ),\n",
    "        annotation_counts=lambda x: x[\"annotations\"].apply(\n",
    "            lambda row: Counter(json.loads(row).values())\n",
    "        ),\n",
    "        annotations=lambda x: x[\"annotations\"].apply(\n",
    "            lambda row: list(json.loads(row).values())\n",
    "        ),\n",
    "    )\n",
    "    # Calculate percentage correct\n",
    "    .assign(\n",
    "        pct_correct=lambda x: x.apply(\n",
    "            lambda row: sum(\n",
    "                a == c for a, c in zip(row[\"answers\"], row[\"correctAnswers\"])\n",
    "            )\n",
    "            / len(row[\"answers\"])\n",
    "            * 100,\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "cloze_df = pd.read_json(\n",
    "    \"../results/cloze_exercises_kl_divergence.jsonl\", lines=True\n",
    ").assign(passageId=lambda x: x.index + 1)\n",
    "\n",
    "df = pd.merge(cloze_df, annotations_df, on=\"passageId\").query(\n",
    "    'method == \"contextuality_plus\"'\n",
    ")\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164acfc-8983-44ba-b579-063f95027fba",
   "metadata": {},
   "source": [
    "# Test Restricted Generation\n",
    "\n",
    "Only choose gaps whose lemmatized form appears in the source text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ba1b20-275f-462a-8e0a-42e87fb97ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualityGapper:\n",
    "    def __init__(self, model_name: str = \"answerdotai/ModernBERT-large\"):\n",
    "        # Load SpaCy for sentence splitting and preprocessing\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Load model and tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.min_blank_distance = 7  # Minimum distance between blanks\n",
    "\n",
    "        # Minimum log-predictability of alternatives\n",
    "        self.min_predictability = np.log(0.05)\n",
    "\n",
    "        # Part-of-Speech Blacklist (do not delete these words)\n",
    "        self.blacklist = [\n",
    "            \"PROPN\",  # Proper nouns\n",
    "            \"NUM\",  # Numbers\n",
    "            \"PUNCT\",  # Punctuation\n",
    "            \"SYM\",  # Symbols\n",
    "            \"X\",  # Other\n",
    "        ]\n",
    "\n",
    "    def _get_leading_ws_tokens(self, doc: Doc) -> list[str]:\n",
    "        \"\"\"The ModernBERT Tokenizer will work fine if we give it tokens with leading spaces.\n",
    "        SpaCy normally handles whitespace in terms of trailing space.\"\"\"\n",
    "        if not len(doc):\n",
    "            return [\"\"]\n",
    "\n",
    "        tokens = [doc[0].text]\n",
    "        # For tokens after the 0th, prepend trailing whitespace from the previous token.\n",
    "        tokens += [doc[i - 1].whitespace_ + doc[i].text for i in range(1, len(doc))]\n",
    "        return tokens\n",
    "\n",
    "    def get_token_mappings(self, tokens: list[str]) -> dict[int, list[int]]:\n",
    "        \"\"\"Get mappings between word positions and token positions\"\"\"\n",
    "        # Tokenize while keeping track of word IDs\n",
    "        tokenized = self.tokenizer(\n",
    "            tokens, return_tensors=\"pt\", is_split_into_words=True\n",
    "        )\n",
    "        word_ids = tokenized.word_ids()\n",
    "\n",
    "        # Create mapping from word position to token positions\n",
    "        word_to_tokens = defaultdict(list)\n",
    "\n",
    "        for token_idx, word_idx in enumerate(word_ids):\n",
    "            if word_idx is not None:\n",
    "                word_to_tokens[word_idx].append(token_idx)\n",
    "\n",
    "        return word_to_tokens\n",
    "\n",
    "    def get_masked_logits(\n",
    "        self, tokens: list[str], mask_idx: int\n",
    "    ) -> tuple[torch.Tensor, int]:\n",
    "        \"\"\"Get model logits for a masked position in text\"\"\"\n",
    "        # Get the word tokens and their alignment info\n",
    "        word_to_tokens = self.get_token_mappings(tokens)\n",
    "\n",
    "        # Find all token positions for the word we want to mask\n",
    "        token_positions = word_to_tokens[mask_idx]\n",
    "\n",
    "        # Create masked version of the text\n",
    "        input_ids = self.tokenizer(\n",
    "            tokens, is_split_into_words=True, return_tensors=\"pt\"\n",
    "        ).input_ids[0]\n",
    "        masked_ids = input_ids.clone()\n",
    "\n",
    "        # ID of the first subword token that we masked\n",
    "        first_token_id = input_ids[token_positions[0]]\n",
    "\n",
    "        # Mask all tokens corresponding to our target word\n",
    "        masked_ids[token_positions] = self.tokenizer.mask_token_id\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = self.model(input_ids.unsqueeze(0).to(self.device))\n",
    "\n",
    "        # Get logits\n",
    "        logits = outputs.logits[0, token_positions, :]\n",
    "\n",
    "        return logits, first_token_id\n",
    "\n",
    "    def get_contextuality_score(\n",
    "        self,\n",
    "        page_doc: Doc,\n",
    "        summary_doc: Doc,\n",
    "        sent: Span,\n",
    "        tok: Token,\n",
    "        method: str = \"kl\",\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate contextuality score for a word position using full page context\n",
    "\n",
    "        Args:\n",
    "            page_doc: The full page text as a spaCy Doc\n",
    "            summary_doc: The summary text as a spaCy Doc\n",
    "            sent: The sentence from the summary containing the token\n",
    "            tok: The token from the summary to evaluate\n",
    "            method: \"kl\" for kl-divergence or \"contextuality\" for contextuality score\n",
    "\n",
    "        Returns:\n",
    "            Contextuality score\n",
    "        \"\"\"\n",
    "\n",
    "        # Get logits for both full text and sentence text\n",
    "        # For the full text context, we use the page + summary\n",
    "        full_toks = self._get_leading_ws_tokens(page_doc) + self._get_leading_ws_tokens(\n",
    "            summary_doc\n",
    "        )\n",
    "        full_pos = len(page_doc) + tok.i  # Position of token in full document\n",
    "        full_logits, word_id = self.get_masked_logits(full_toks, full_pos)\n",
    "\n",
    "        # For the local context, we use just the sentence from the summary\n",
    "        sent_pos = tok.i - sent.start  # Position of token in the sentence\n",
    "        sent_logits, _ = self.get_masked_logits([tok.text for tok in sent], sent_pos)\n",
    "\n",
    "        # Calculate probabilities using first sub-word token\n",
    "        full_probs = torch.softmax(full_logits[0], dim=0)\n",
    "        sent_probs = torch.softmax(sent_logits[0], dim=0)\n",
    "\n",
    "        p = full_probs[word_id]\n",
    "        q = sent_probs[word_id]\n",
    "\n",
    "        if method == \"kl\":\n",
    "            # KL-divergence is p*log(p/q)\n",
    "            score = float(p * torch.log2(p / q))\n",
    "        elif method == \"contextuality\":\n",
    "            # Contextuality is distance between full-text and sentence probability\n",
    "            score = float(p - q)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown method.\")\n",
    "\n",
    "        return score\n",
    "\n",
    "    def choose_blank_positions(\n",
    "        self, page_doc: Doc, summary_doc: Doc, num_blanks: int\n",
    "    ) -> list[int]:\n",
    "        \"\"\"Choose positions to blank in the summary based on contextuality scores with full page\"\"\"\n",
    "        scores = []\n",
    "        valid_positions = []\n",
    "\n",
    "        page_lemmas = {tok.lemma_ for tok in page_doc}\n",
    "\n",
    "        # Calculate scores for each position in the summary\n",
    "        for i, sent in enumerate(summary_doc.sents):\n",
    "            if i == 0:\n",
    "                continue  # Skip first sentence\n",
    "            for tok in sent:\n",
    "                if (\n",
    "                    len(tok.text) < 3\n",
    "                    or tok.pos_ in self.blacklist\n",
    "                    or tok.is_stop\n",
    "                    or not tok.text.isalpha()\n",
    "                    or tok.lemma_ not in page_lemmas\n",
    "                ):\n",
    "                    scores.append(-float(\"inf\"))\n",
    "                else:\n",
    "                    # Calculate contextuality using both the full page and summary\n",
    "                    score = self.get_contextuality_score(\n",
    "                        page_doc, summary_doc, sent, tok\n",
    "                    )\n",
    "                    scores.append(score)\n",
    "                valid_positions.append(tok.i)\n",
    "\n",
    "        # Convert to numpy for easier manipulation\n",
    "        scores = np.array(scores)\n",
    "\n",
    "        # Choose positions greedily while maintaining minimum distance\n",
    "        positions = []\n",
    "        for _ in range(num_blanks):\n",
    "            if np.all(scores == -float(\"inf\")):\n",
    "                break\n",
    "\n",
    "            # Choose highest scoring position\n",
    "            idx = np.argmax(scores)\n",
    "            pos = valid_positions[idx]\n",
    "            positions.append(pos)\n",
    "\n",
    "            # Zero out scores within minimum distance\n",
    "            start = max(0, idx - self.min_blank_distance)\n",
    "            end = min(len(scores), idx + self.min_blank_distance + 1)\n",
    "            scores[start:end] = -float(\"inf\")\n",
    "\n",
    "        return sorted(positions)\n",
    "\n",
    "    def get_alternates(self, tokens: list[str], topk=5) -> list[dict]:\n",
    "        \"\"\"Get top k predictions for the masked positions in tokens\n",
    "\n",
    "        Returns:\n",
    "            List of dictionaries, one per masked position, with candidate words and their probabilities\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "\n",
    "        # Find all mask positions\n",
    "        mask_positions = [i for i, token in enumerate(tokens) if token == \"[MASK]\"]\n",
    "\n",
    "        for mask_pos in mask_positions:\n",
    "            word_candidates = {}\n",
    "\n",
    "            # Try different mask lengths (1, 2, or 3 tokens)\n",
    "            for mask_length in range(1, 4):\n",
    "                # Replace the single mask with multiple if needed\n",
    "                masked_tokens = (\n",
    "                    tokens[:mask_pos]\n",
    "                    + [\"[MASK]\"] * mask_length\n",
    "                    + tokens[mask_pos + 1 :]\n",
    "                )\n",
    "\n",
    "                # Get initial predictions for first token\n",
    "                current_candidates = []\n",
    "                logits, _ = self.get_masked_logits(masked_tokens, mask_pos)\n",
    "                probs = torch.softmax(logits[0], dim=0)\n",
    "                top_values, top_indices = torch.topk(probs, topk)\n",
    "\n",
    "                # Start with first token candidates\n",
    "                for idx, prob in zip(top_indices.tolist(), top_values.tolist()):\n",
    "                    current_candidates.append(([idx], prob))\n",
    "\n",
    "                # Build up multi-token predictions if needed\n",
    "                for token_idx in range(1, mask_length):\n",
    "                    new_candidates = []\n",
    "                    for token_ids, prob in current_candidates:\n",
    "                        # Fill in what we've predicted so far\n",
    "                        partial_filled = tokens.copy()\n",
    "                        filled_text = self.tokenizer.decode(token_ids)\n",
    "                        remaining_masks = mask_length - token_idx\n",
    "\n",
    "                        partial_filled = (\n",
    "                            tokens[:mask_pos]\n",
    "                            + [filled_text]\n",
    "                            + [\"[MASK]\"] * remaining_masks\n",
    "                            + tokens[mask_pos + 1 :]\n",
    "                        )\n",
    "\n",
    "                        # Get prediction for next position\n",
    "                        next_logits, _ = self.get_masked_logits(\n",
    "                            partial_filled, mask_pos + 1\n",
    "                        )\n",
    "                        next_probs = torch.softmax(next_logits[0], dim=0)\n",
    "                        next_values, next_indices = torch.topk(next_probs, 1)\n",
    "\n",
    "                        # Add to candidates\n",
    "                        new_token_ids = token_ids + [next_indices[0].item()]\n",
    "                        new_prob = prob * next_values[0].item()\n",
    "                        new_candidates.append((new_token_ids, new_prob))\n",
    "\n",
    "                    current_candidates = new_candidates\n",
    "\n",
    "                # Add final decoded words\n",
    "                for token_ids, prob in current_candidates:\n",
    "                    word = self.tokenizer.decode(token_ids).strip()\n",
    "                    if \" \" in word:\n",
    "                        # Word contains a space (is actually multiple words)\n",
    "                        continue\n",
    "                    if word not in word_candidates or prob > word_candidates[word]:\n",
    "                        word_candidates[word] = prob\n",
    "\n",
    "            # Sort candidates by probability\n",
    "            sorted_candidates = sorted(\n",
    "                word_candidates.items(), key=lambda x: x[1], reverse=True\n",
    "            )\n",
    "            predictions.append({word: prob for word, prob in sorted_candidates[:topk]})\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def generate_cloze(\n",
    "        self,\n",
    "        summary_text: str,\n",
    "        page_text: str = \"\",\n",
    "        num_blanks: int = 10,\n",
    "    ) -> tuple[str, list[str], list[dict[str, float]]]:\n",
    "        \"\"\"Generate a cloze text from summary using page for context\n",
    "\n",
    "        Args:\n",
    "            page_text: The full page text\n",
    "            summary_text: The summary text to create gaps in\n",
    "            num_blanks: Number of blanks to create\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (cloze_text, answers, alternates)\n",
    "        \"\"\"\n",
    "        # Process both texts\n",
    "        page_doc = self.nlp(page_text)\n",
    "        summary_doc = self.nlp(summary_text)\n",
    "\n",
    "        # Choose positions to blank in the summary\n",
    "        masked_positions = self.choose_blank_positions(\n",
    "            page_doc, summary_doc, num_blanks\n",
    "        )\n",
    "\n",
    "        # Get the answers (the original words that will be blanked)\n",
    "        answers = [summary_doc[pos].text for pos in masked_positions]\n",
    "\n",
    "        # Replace tokens with mask\n",
    "        summary_tokens = np.array(self._get_leading_ws_tokens(summary_doc))\n",
    "        summary_tokens[masked_positions] = \"[MASK]\"\n",
    "        summary_tokens = summary_tokens.tolist()\n",
    "\n",
    "        # Construct cloze token input for gap predictions\n",
    "        cloze_tokens = self._get_leading_ws_tokens(page_doc) + summary_tokens\n",
    "\n",
    "        # Collect gaps\n",
    "        gaps = []\n",
    "        for tok in summary_doc:\n",
    "            if tok.i in masked_positions:\n",
    "                gaps.append((tok.text, tok.idx, len(tok.text)))\n",
    "\n",
    "        return gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e011595b-5546-4f7a-9621-5d97a9b20fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gapper = ContextualityGapper(model_name=\"answerdotai/ModernBERT-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5486dbfa-17cb-4cea-876d-295905b0817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda_envs/hf/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:194: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "restricted = []\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df)):\n",
    "    restricted.append(gapper.generate_cloze(row.summary, page_text=row.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c1dfc97-c4a7-4fa5-8926-cf6e34d7bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"restricted_answers\"] = [\n",
    "    [answer for answer, _, _ in answer_list] for answer_list in restricted\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807ab4a-9ed0-4bba-bb02-5ce23eb03b2a",
   "metadata": {},
   "source": [
    "## Compare Gaps\n",
    "\n",
    "Without collecting additional annotations, the best we can do is look at which gaps would be retained with this method and which gaps would be removed.\n",
    "\n",
    "If this method disproportionately removes gaps that were more difficult to answer, then we can infer that the lemma overlap restriction will make the cloze exercise easier (which is what we want).\n",
    "\n",
    "First, we see that the lemma overlap constraint does not substantially decrease the number of gaps that are generated (8.65 gaps per exercise vs. 9 gaps per exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e35b07f-3b6a-406c-b053-768aa4f3c4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    23.000000\n",
       "mean      8.652174\n",
       "std       1.112274\n",
       "min       7.000000\n",
       "25%       7.500000\n",
       "50%       9.000000\n",
       "75%       9.000000\n",
       "max      10.000000\n",
       "Name: restricted_answers, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    23.000000\n",
       "mean      9.000000\n",
       "std       0.738549\n",
       "min       8.000000\n",
       "25%       8.500000\n",
       "50%       9.000000\n",
       "75%       9.500000\n",
       "max      10.000000\n",
       "Name: correctAnswers, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.restricted_answers.str.len().describe())\n",
    "display(df.correctAnswers.str.len().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d279c1-0770-4e7b-abad-6cc564cb4b35",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The lemma overlap restriction retains 44% of gaps that are \"source-predictable\" (ideal), and removes 31% of gaps that were scored as \"unpredictable\" (bad gaps). This is a good indication that the lemma overlap constraint improves the cloze exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "686c5219-983b-4c0b-94d3-08cfb724482d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained gaps\n",
      "[('passage', 0.18), ('sentence', 0.3), ('source', 0.44), ('unpredictable', 0.08)]\n",
      "\n",
      "Removed gaps\n",
      "[('passage', 0.17), ('sentence', 0.43), ('source', 0.09), ('unpredictable', 0.31)]\n"
     ]
    }
   ],
   "source": [
    "unchanged = []\n",
    "removed = []\n",
    "# added = []\n",
    "\n",
    "\n",
    "def normalize_counter(c: Counter):\n",
    "    total = sum(c.values())\n",
    "    for key in c:\n",
    "        c[key] = round(c[key] / total, 2)\n",
    "    return c\n",
    "\n",
    "\n",
    "for row in df.itertuples():\n",
    "    for answer, rating in zip(row.correctAnswers, row.annotations):\n",
    "        if answer in row.restricted_answers:\n",
    "            unchanged.append(rating)\n",
    "        else:\n",
    "            removed.append(rating)\n",
    "\n",
    "print(\"Retained gaps\")\n",
    "print(sorted(normalize_counter(Counter(unchanged)).items()))\n",
    "print(\"\\nRemoved gaps\")\n",
    "print(sorted(normalize_counter(Counter(removed)).items()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
