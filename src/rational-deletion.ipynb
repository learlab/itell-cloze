{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "670e1086-2b3b-4e72-9a38-c21463a2d53a",
   "metadata": {},
   "source": [
    "# Rational Deletion\n",
    "\n",
    "The following approach is adapted from [Ondov et al. (2024)](https://aclanthology.org/2024.naacl-long.220/).\n",
    "\n",
    "The basic idea is to measure word probabilities with a masked language model in two ways: the first probability estimate uses the entire context and the second probability estimate uses only the local (sentence) context. We want words that are predictable given the full context, but cannot be easily guessed using only the local context. The distance between these two probability estimates indicates whether the word is more predictable in the full context than the local context.\n",
    "\n",
    "The approach handles simultaneous masking of subword tokens and allows for the following configuration:\n",
    "  - Target number of blanks to generate\n",
    "  - Minimum distance between blanks\n",
    "  - Blacklisting of part of speech tags to prevent masking of high entropy words like proper nouns and numbers\n",
    "\n",
    "We also collect predictions for other possible words. This includes a greedy search algorithm to identify whole-word predictions in the event of sub-word tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8cbc808f-5495-4a09-94e0-7fceadf1779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from pprint import pp\n",
    "from typing import List, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "class RationalClozeGenerator:\n",
    "    def __init__(self, model_name: str = \"answerdotai/ModernBERT-large\"):\n",
    "        # Load SpaCy for sentence splitting and preprocessing\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Load model and tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.min_blank_distance = 7 # Minimum distance between blanks\n",
    "        # Minimum predictability of alternatives\n",
    "        # Use log probs to avoid underflow\n",
    "        self.min_predictability = np.log(0.05)\n",
    "\n",
    "        # Part-of-Speech Blacklist (do not delete these words)\n",
    "        self.blacklist = [\n",
    "            \"PROPN\", # Proper nouns\n",
    "            \"NUM\", # Numbers\n",
    "            \"PUNCT\", # Punctuation\n",
    "            \"SYM\", # Symbols\n",
    "            \"X\", # Other\n",
    "        ]\n",
    "\n",
    "    def get_token_mappings(self, text: str) -> Tuple[List[int], List[int]]:\n",
    "        \"\"\"Get mappings between word positions and token positions\"\"\"\n",
    "        # Tokenize while keeping track of word IDs\n",
    "        tokenized = self.tokenizer(text, return_tensors=\"pt\", is_split_into_words=True)\n",
    "        word_ids = tokenized.word_ids()\n",
    "        \n",
    "        # Create mapping from word position to token positions\n",
    "        word_to_tokens = {}\n",
    "        \n",
    "        for token_idx, word_idx in enumerate(word_ids):\n",
    "            if word_idx is not None:\n",
    "                if word_idx not in word_to_tokens:\n",
    "                    word_to_tokens[word_idx] = []\n",
    "                word_to_tokens[word_idx].append(token_idx)\n",
    "            \n",
    "        return word_to_tokens\n",
    "\n",
    "    def get_masked_logits(self, span: Doc|Span, mask_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Get model logits for a masked position in text\"\"\"\n",
    "        # Get the word tokens and their alignment info\n",
    "        tokens = [tok.text for tok in span]\n",
    "        word_to_tokens = self.get_token_mappings(tokens)\n",
    "        \n",
    "        # Find all token positions for the word we want to mask\n",
    "        token_positions = word_to_tokens[mask_idx]\n",
    "        \n",
    "        # Create masked version of the text\n",
    "        input_ids = self.tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\").input_ids[0]\n",
    "        masked_ids = input_ids.clone()\n",
    "\n",
    "        # ID of the first subword token that we masked\n",
    "        first_token_id = input_ids[token_positions[0]]\n",
    "\n",
    "        # Mask all tokens corresponding to our target word\n",
    "        masked_ids[token_positions] = self.tokenizer.mask_token_id\n",
    "\n",
    "        # Get model outputs\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids.unsqueeze(0).to(self.device))\n",
    "            \n",
    "        # Get logits \n",
    "        logits = outputs.logits[0, token_positions, :]\n",
    "\n",
    "        return logits, first_token_id\n",
    "\n",
    "    def get_contextuality_score(self, doc: Doc, sent: Span, tok: Token) -> float:\n",
    "        \"\"\"Calculate contextuality score for a word position\"\"\"\n",
    "        # Get logits for both full text and sentence contexts\n",
    "        full_logits, word_id = self.get_masked_logits(doc, tok.i)\n",
    "        sent_logits, _ = self.get_masked_logits(sent, tok.i - sent.start)\n",
    "        \n",
    "        # Calculate probabilities using first sub-word token\n",
    "        full_probs = torch.softmax(full_logits[0], dim=0)\n",
    "        sent_probs = torch.softmax(sent_logits[0], dim=0)\n",
    "\n",
    "        # Contextuality is distance between full-text and sentence probability\n",
    "        if float(full_probs[word_id].log()) > self.min_predictability:\n",
    "            score = float(full_probs[word_id].log() - sent_probs[word_id].log())\n",
    "        else:\n",
    "            score = float(\"-inf\")\n",
    "\n",
    "        return score\n",
    "\n",
    "    def choose_blank_positions(self, doc: Doc, num_blanks: int) -> list[int]:\n",
    "        \"\"\"Choose positions to blank based on contextuality scores\"\"\"\n",
    "        scores = []\n",
    "        valid_positions = []\n",
    "        \n",
    "        # Calculate scores and get predictions for each position\n",
    "        for sent in doc.sents:\n",
    "            for tok in sent:\n",
    "                if (len(tok.text) < 3 or \n",
    "                    tok.pos_ in self.blacklist or \n",
    "                    tok.is_stop or \n",
    "                    not tok.text.isalpha()):\n",
    "                    scores.append(-float('inf'))\n",
    "                else:\n",
    "                    score = self.get_contextuality_score(doc, sent, tok)\n",
    "                    scores.append(score)\n",
    "                valid_positions.append(tok.i)\n",
    "                \n",
    "        # Convert to numpy for easier manipulation\n",
    "        scores = np.array(scores)\n",
    "        \n",
    "        # Choose positions greedily while maintaining minimum distance\n",
    "        positions = []\n",
    "        for _ in range(num_blanks):\n",
    "            if np.all(scores == -float('inf')):\n",
    "                break\n",
    "                \n",
    "            # Choose highest scoring position\n",
    "            idx = np.argmax(scores)\n",
    "            pos = valid_positions[idx]\n",
    "            positions.append(pos)\n",
    "            \n",
    "            # Zero out scores within minimum distance\n",
    "            start = max(0, idx - self.min_blank_distance)\n",
    "            end = min(len(scores), idx + self.min_blank_distance + 1)\n",
    "            scores[start:end] = -float('inf')\n",
    "\n",
    "        return sorted(positions)\n",
    "\n",
    "    def get_alternates(self, doc: Doc, positions: list[int], k: int = 5) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Get top k predictions greater than self.min_predictability. Uses greedy search\n",
    "        to find the top predictions for whole words when there are multiple subtokens.\n",
    "        \"\"\"\n",
    "        \n",
    "        tokens = [tok.text for tok in doc]\n",
    "        words_to_tokens = self.get_token_mappings(tokens)\n",
    "        input_ids = self.tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\").input_ids[0]\n",
    "        # print(\"Input:\", self.tokenizer.decode(input_ids))\n",
    "\n",
    "        predictions = []\n",
    "        for pos in positions:\n",
    "            # print(\"\\nGapped Word:\", doc[pos])\n",
    "            logits, word_id = self.get_masked_logits(doc, pos)\n",
    "            first_tok_probs = torch.softmax(logits[0], dim=0)\n",
    "            top_probs, top_indices = torch.topk(first_tok_probs, k)\n",
    "            # print(\"Num sub toks:\", logits.shape[0])\n",
    "\n",
    "            # Get topk predictions for multi-token words using greedy sampling\n",
    "            word_predictions = defaultdict(float)\n",
    "            for i in range(k):\n",
    "                prob = top_probs[i]\n",
    "                sub_toks = [top_indices[i].item()]\n",
    "                if prob.log() < self.min_predictability:\n",
    "                    break\n",
    "\n",
    "                remaining_sub_toks = logits.shape[0] - 1\n",
    "                while remaining_sub_toks > 0:\n",
    "                    # Find which subtokens to mask\n",
    "                    # And which subtokens to fill with top prediction\n",
    "                    tok_idxs = words_to_tokens[pos]\n",
    "                    to_fill = tok_idxs[:-remaining_sub_toks]\n",
    "                    to_mask = tok_idxs[-remaining_sub_toks:]\n",
    "                    next_sub_tok_idx = tok_idxs[-remaining_sub_toks]\n",
    "\n",
    "                    # Mask and fill subtokens as needed\n",
    "                    temp_ids = input_ids.detach().clone()\n",
    "                    temp_ids[to_fill] = torch.tensor(sub_toks, dtype=torch.long)\n",
    "                    temp_ids[to_mask] = self.tokenizer.mask_token_id\n",
    "\n",
    "                    # print(\"Masked Token:\", self.tokenizer.decode(input_ids[next_sub_tok_idx]))\n",
    "                    # print(\"Masked Token ID:\", input_ids[next_sub_tok_idx])\n",
    "                    # print(\"Mask:\", self.tokenizer.decode(temp_ids[next_sub_tok_idx]))\n",
    "                    \n",
    "                    # Collect predictions conditioned on previous subtokens\n",
    "                    with torch.no_grad():\n",
    "                        outputs = self.model(temp_ids.unsqueeze(0).to(self.device))\n",
    "                    next_sub_tok_logits = outputs.logits[0, next_sub_tok_idx, :]\n",
    "                    next_sub_tok_id = next_sub_tok_logits.softmax(dim=0).argmax(axis=-1).item()\n",
    "                    kprobs, kidxs = torch.topk(next_sub_tok_logits.softmax(dim=0), 5)\n",
    "\n",
    "                    # print(\"TopK:\", kidxs)\n",
    "                    # print(\"Pred_id:\", next_sub_tok_id)\n",
    "                    # print(\"Prediction:\", self.tokenizer.decode(next_sub_tok_id))\n",
    "\n",
    "                    sub_toks.append(next_sub_tok_id)\n",
    "\n",
    "                    remaining_sub_toks -= 1\n",
    "\n",
    "                # Assemble subtokens into word string\n",
    "                # Normalize the word string\n",
    "                # Different forms should be treated as the same answer:\n",
    "                # e.g., \"statistical\", \" Statistical\", and \"Statistical\"\n",
    "                token = self.tokenizer.decode(sub_toks).strip().lower()\n",
    "\n",
    "                # Accumulate probabilities\n",
    "                word_predictions[token] += float(prob)\n",
    "            \n",
    "            predictions.append(word_predictions)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def generate_cloze(self, text: str, num_blanks: int) -> tuple[str, list[str]]:\n",
    "        \"\"\"Generate a cloze text with blanks and return answers\"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        positions = self.choose_blank_positions(doc, num_blanks)\n",
    "        answers = [doc[pos].text for pos in positions]\n",
    "\n",
    "        alternates = self.get_alternates(doc, positions)\n",
    "\n",
    "        # Replace words with blanks\n",
    "        cloze_text = \"\"\n",
    "        for tok in doc:\n",
    "            if tok.i in positions:\n",
    "                cloze_text += \"_\" * len(tok.text) + tok.whitespace_\n",
    "            else:\n",
    "                cloze_text += tok.text_with_ws\n",
    "            \n",
    "        return cloze_text, answers, alternates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90d70440-6fc3-4957-8620-087b616a59f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = RationalClozeGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb920209-f3a2-4f37-bc59-02df9b16c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloze text:\n",
      "Embarking on an international assignment, whether for work or study, entails navigating a complex \n",
      "landscape of emotional and cultural challenges. _________ marked by intrigue and excitement, expatriates often \n",
      "face culture shock and a period of adjustment before embracing their host culture. This journey necessitates \n",
      "meticulous preparation akin to other significant life changes, emphasizing the importance of ____________, \n",
      "language proficiency, and cultural understanding. Successful ___________ are those who, rather than succumbing \n",
      "to frustration, leverage these experiences to enhance their personal and professional growth. The process of \n",
      "acculturation involves various emotional stages, including initial elation, culture shock, and eventual acceptance, \n",
      "followed by the challenges of reentry into one's native culture. _______ the potential for early termination of \n",
      "assignments due to family or ________ issues, careful consideration and preparation can mitigate these risks, \n",
      "making _____________ experience a valuable asset both personally and professionally.\n",
      "\n",
      "Answers:\n",
      "{'Initially': {'initially': 1.0},\n",
      " 'adaptability': {'adaptation': 1.0},\n",
      " 'expatriates': {'expatriates': 1.0},\n",
      " 'Despite': {'despite': 0.91, 'given': 0.06},\n",
      " 'personal': {'personal': 1.0},\n",
      " 'international': {'international': 0.75}}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"The Cloze procedure, first introduced by Taylor, is a widely used method for creating reading \n",
    "comprehension tests inspired by the Gestalt principle of closure. Though many variations have been \n",
    "introduced and studied, the core concept is to mask words in prose and task the subject with providing \n",
    "the missing words.\"\"\"\n",
    "\n",
    "text = \"\"\"Embarking on an international assignment, whether for work or study, entails navigating a complex \n",
    "landscape of emotional and cultural challenges. Initially marked by intrigue and excitement, expatriates often \n",
    "face culture shock and a period of adjustment before embracing their host culture. This journey necessitates \n",
    "meticulous preparation akin to other significant life changes, emphasizing the importance of adaptability, \n",
    "language proficiency, and cultural understanding. Successful expatriates are those who, rather than succumbing \n",
    "to frustration, leverage these experiences to enhance their personal and professional growth. The process of \n",
    "acculturation involves various emotional stages, including initial elation, culture shock, and eventual acceptance, \n",
    "followed by the challenges of reentry into one's native culture. Despite the potential for early termination of \n",
    "assignments due to family or personal issues, careful consideration and preparation can mitigate these risks, \n",
    "making international experience a valuable asset both personally and professionally.\"\"\"\n",
    "\n",
    "cloze_text, answers, preds = generator.generate_cloze(text, num_blanks=6)\n",
    "print(\"Cloze text:\")\n",
    "print(cloze_text)\n",
    "print(\"\\nAnswers:\")\n",
    "answer_dict = {answer: {word: round(prob,2) for word, prob in pred.items()} for answer, pred in zip(answers, preds)}\n",
    "pp(answer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e0509b5c-8b69-4e61-8baa-b0b8e4adc912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-experimental-and-clinical-psychologists\n",
      "================================================================================\n",
      "Cloze text:\n",
      "Experimental psychologists, _________ holding doctoral and master's degrees, conduct scientific research in various psychology subfields, often collaborating with students at universities. While some are trained clinicians, most focus on non-clinical areas such as cognitive or ______ psychology. Their research is crucial for understanding human behavior and developing _________ knowledge, which is vital for clinical practice. The interplay between research and practice is significant, as psychological disorders are ___________ testable. The effectiveness of treatments, like psychotherapy, relies on __________ validation. The clinical psychology community debates the emphasis on empirically _________ treatments, but there is consensus on the need for a scientific approach to ensure effective diagnosis and treatment.\n",
      "\n",
      "Answers:\n",
      "{'primarily': {'primarily': 1.0},\n",
      " 'social': {'social': 0.95},\n",
      " 'empirical': {'empirical': 1.0},\n",
      " 'empirically': {'empirically': 1.0},\n",
      " 'scientific': {'scientific': 1.0},\n",
      " 'supported': {'supported': 0.88}}\n",
      "================================================================================\n",
      "12-analyzing-the-data\n",
      "================================================================================\n",
      "Cloze text:\n",
      "Descriptive statistics are tools used to organize and summarize data, including measures of _______ tendency like mean, median, and mode, as well as measures of dispersion such as range, standard deviation, and variance. These statistics help describe the central point and variability within a data set. In experimental research, means and ________ deviations are calculated to compare groups, while non-experimental research may use percentages and correlation coefficients to explore relationships between variables. Inferential statistics, on the other ____, allow researchers to draw conclusions about a population based on sample data, determining statistical significance to infer real effects. ___________ significance indicates that results are unlikely due to chance, with a typical threshold of 5% for determining significance. ___________ must be cautious of errors; a Type I error occurs when a false positive is concluded, whereas a Type II error involves missing a real effect. _________ these errors is crucial for accurate statistical conclusions.\n",
      "\n",
      "Answers:\n",
      "{'central': {'central': 0.91},\n",
      " 'standard': {'standard': 1.0},\n",
      " 'hand': {'hand': 0.92},\n",
      " 'Statistical': {'statistical': 0.53, '': 0.14},\n",
      " 'Researchers': {'residences': 1.0},\n",
      " 'Balancing': {'balancing': 0.87}}\n",
      "================================================================================\n",
      "18-6-styles-of-management\n",
      "================================================================================\n",
      "Cloze text:\n",
      "Douglas McGregor's influential book, The Human Side of Enterprise, __________ Theory X and Theory Y, which are based on Maslow's hierarchy of _____. Theory X assumes that workers are inherently lazy, motivated solely by basic needs, and require strict supervision, leading managers to adopt an authoritarian style. Conversely, Theory Y suggests that workers are self-motivated and thrive on responsibility, promoting a more _____________ management approach. William Ouchi's Theory Z integrates elements of both theories, emphasizing worker participation, skill ___________, and loyalty, drawing from American and Japanese __________ practices. These theories offer foundational insights into diverse __________ styles and intercultural organizational understanding.\n",
      "\n",
      "Answers:\n",
      "{'introduces': {'introduces': 1.0},\n",
      " 'needs': {'needs': 0.58},\n",
      " 'participative': {'participative': 0.82},\n",
      " 'development': {'development': 0.96},\n",
      " 'management': {'management': 0.95}}\n",
      "================================================================================\n",
      "18-2-how-to-understand-intercultural-communication\n",
      "================================================================================\n",
      "Cloze text:\n",
      "Edward T. Hall, an influential American anthropologist, transformed the study of intercultural communication by emphasizing individual interactions over generalized cultural ____________. His insights emerged from his multicultural experiences in the American Southwest and global travels, including his work with the U.S. State Department. Hall's contributions include focusing on local perspectives, acknowledging the importance of ________ experience, and understanding that individuals within a culture may diverge from _____________ norms. He highlighted the pitfalls of stereotypes, as explored by psychologist Gordon Allport, noting how they oversimplify ________ and hinder genuine understanding. Hall advocated for firsthand cultural experiences to ______ learning and mitigate prejudice, urging openness to diverse ____________ and personal growth through direct interaction with unfamiliar cultures.\n",
      "\n",
      "Answers:\n",
      "{'observations': {'observations': 1.0},\n",
      " 'personal': {'personal': 0.99},\n",
      " 'stereotypical': {'stereotypical': 1.0},\n",
      " 'cultures': {'cultures': 1.0},\n",
      " 'foster': {'foster': 1.0},\n",
      " 'perspectives': {'perspectives': 1.0}}\n",
      "================================================================================\n",
      "4-control-room-operator-cro-training\n",
      "================================================================================\n",
      "Cloze text:\n",
      "To qualify as a Control Room Operator (CRO), candidates must meet specific training requirements ________ in the provided document. Those who fail the CRO fundamentals ______ can retake it with STL approval, and further ________ require recommendations and support from various authorities before retesting. __________ must also be qualified on related field jobs prior to Post-CRO Fundamentals training, during which they are mentored and undergo unit-specific console training using simulators. Successful completion of ________ is verified through the LMS system, and all documentation must be properly filed. ____ must maintain qualifications by working shifts or completing simulator sessions each quarter, and they are required to pass refresher exams every three years with at least an 80% score. Failure to meet training or exam requirements is addressed by a Board of Review to determine corrective actions.\n",
      "\n",
      "Answers:\n",
      "{'outlined': {'outlined': 1.0},\n",
      " 'course': {'course': 0.17, '.': 0.16, '': 0.11},\n",
      " 'failures': {'failures': 1.0},\n",
      " 'Candidates': {'candidates': 1.0},\n",
      " 'training': {'training': 0.92},\n",
      " 'CROs': {'cros': 0.94}}\n",
      "================================================================================\n",
      "appendices\n",
      "================================================================================\n",
      "Cloze text:\n",
      "_________ being generated...\n",
      "\n",
      "Answers:\n",
      "{'Currently': {'currently': 0.31, '': 0.12}}\n",
      "================================================================================\n",
      "7-other-training\n",
      "================================================================================\n",
      "Cloze text:\n",
      "The outlined training ____________ for operations personnel in a Refinery Business Unit emphasize the necessary qualifications for working in a new plant. The Capital Project Team is tasked with developing and __________ training materials, with Learning & Development (L&D) personnel providing subject matter expertise as needed. Additionally, training _______ to plant changes and procedure updates is _______ through the Management of Change (MOC) system and the Document Management System. _______ matter experts develop and deliver this training, ensuring operators are informed of changes impacting their roles. __________ of training is documented using various electronic tools.\n",
      "\n",
      "Answers:\n",
      "{'requirements': {'requirements': 1.0},\n",
      " 'delivering': {'delivering': 1.0},\n",
      " 'related': {'related': 1.0},\n",
      " 'managed': {'managed': 1.0},\n",
      " 'Subject': {'subject': 0.93},\n",
      " 'Completion': {'completion': 0.62}}\n",
      "================================================================================\n",
      "9-unit-school-instructors-and-otj-trainers\n",
      "================================================================================\n",
      "Cloze text:\n",
      "The selection process for Unit School Instructors ____ to ensure qualified individuals are chosen to deliver crucial training for developing competent _________. Candidates must be approved by the STL, demonstrate an interest in instruction, and have completed a Train-The-Trainer class. They should have at least one year of experience at the FQO level, effective communication ______, and knowledge of safety and process protocols. Basic computer skills and ___________ with refinery intranet resources are also required. ___________ work with Unit Field Trainers to update training materials and maintain records. The UFT maintains an Instructor Directory to help STLs select eligible trainers for conducting shadow training. During this phase, ________ are guided by qualified OTJ trainers and use various resources to facilitate learning, including the Break-in Guide and Electronic Operating Manual.\n",
      "\n",
      "Answers:\n",
      "{'aims': {'aims': 0.52, 'oughtis': 0.18, 'designed': 0.09},\n",
      " 'operators': {'operatives': 0.97},\n",
      " 'skills': {'skills': 1.0},\n",
      " 'familiarity': {'familiarity': 1.0},\n",
      " 'Instructors': {'instructors': 1.0},\n",
      " 'trainees': {'trainees': 1.0}}\n",
      "================================================================================\n",
      "7-a-model-of-scientific-research-in-psychology\n",
      "================================================================================\n",
      "Cloze text:\n",
      "The text outlines a model of scientific ________ in psychology, exemplified by studies conducted by ___________ like Mehl and David Strayer. Mehl's team explored gender ___________ in talkativeness, prompted by societal stereotypes and literature gaps, leading to an empirical study that found minimal ___________ and spurred further research questions. Concurrently, Strayer's work in cognitive neuroscience examined the impact of cell phone use on driving, revealing significant ____________ and influencing policy changes. His research demonstrated the dangers of both handheld and hands-free devices, likening texting while driving to driving under the influence. These studies highlight the cyclical nature of scientific inquiry, where new research both addresses existing questions and generates new ones, contributing to a broader understanding of human behavior and _________ public policy.\n",
      "\n",
      "Answers:\n",
      "{'research': {'research': 1.0},\n",
      " 'researchers': {'researchers': 1.0},\n",
      " 'differences': {'differences': 1.0},\n",
      " 'distractions': {'distributions': 1.0},\n",
      " 'informing': {'informing': 1.0}}\n",
      "================================================================================\n",
      "18-7-the-international-assignment\n",
      "================================================================================\n",
      "Cloze text:\n",
      "Embarking on an international assignment, whether for work or study, entails navigating a complex landscape of emotional and cultural challenges. Initially marked by intrigue and excitement, expatriates often face culture _____ and a period of adjustment before embracing their host culture. This journey necessitates meticulous preparation akin to other significant life changes, emphasizing the importance of adaptability, language proficiency, and cultural understanding. Successful ___________ are those who, rather than succumbing to frustration, leverage these experiences to enhance their personal and professional growth. The process of acculturation involves various emotional stages, including initial elation, _______ shock, and eventual acceptance, followed by the challenges of reentry into one's native culture. _______ the potential for early termination of assignments due to family or ________ issues, careful consideration and preparation can mitigate these risks, making _____________ experience a valuable asset both personally and professionally.\n",
      "\n",
      "Answers:\n",
      "{'shock': {'shock': 0.96},\n",
      " 'expatriates': {'expatriates': 1.0},\n",
      " 'culture': {'culture': 0.99},\n",
      " 'Despite': {'despite': 0.86, 'given': 0.1},\n",
      " 'personal': {'personal': 1.0},\n",
      " 'international': {'international': 0.48, 'them': 0.05}}\n",
      "================================================================================\n",
      "18-3-common-cultural-characteristics\n",
      "================================================================================\n",
      "Cloze text:\n",
      "The text explores the _________ and evolution of cultures within educational, professional, and broader ________ contexts. It highlights how individuals transition from outsiders to full members through rituals and rites of initiation, which can be informal, like joining _________ for lunch, or formal, like religious ___________. In business, culture is crucial as communication fosters community, with symbolic elements such as office spaces or attire indicating status and power. Cultures also employ unique vocabularies and _______, which can both bind and constrain groups, emphasizing that adaptability is vital as cultural practices and norms evolve over time. The dynamic nature of cultures reflects the constant change in _____________ contexts and societal structures.\n",
      "\n",
      "Answers:\n",
      "{'formation': {'formation': 1.0},\n",
      " 'societal': {'societal': 1.0},\n",
      " 'coworkers': {'cafeterias': 1.0},\n",
      " 'ordinations': {'ordination': 0.98},\n",
      " 'rituals': {'rituals': 1.0},\n",
      " 'communication': {'communication': 0.58}}\n",
      "================================================================================\n",
      "19-1-what-is-a-group\n",
      "================================================================================\n",
      "Cloze text:\n",
      "_________ being generated...\n",
      "\n",
      "Answers:\n",
      "{'Currently': {'currently': 0.31, '': 0.12}}\n",
      "================================================================================\n",
      "8-interns\n",
      "================================================================================\n",
      "Cloze text:\n",
      "The intern assignment at Chevron spans one semester, or 12-14 weeks, during which operations interns are integrated with a specific crew to gain insights into the _____________ environment. Interns are expected to adhere to the same standards and ________ as full-time employees but are not considered qualified operators. Their tasks are limited and supervised by _________ operators, and they cannot respond to emergencies. Successful interns may transition to full-____ operator trainees, contingent on meeting program ____________, business needs, and HR approval. The O&M Internship Guide outlines the transition process, and an early promotion may be possible if _________ retention and performance are satisfactory.\n",
      "\n",
      "Answers:\n",
      "{'manufacturing': {'manufacturing': 1.0},\n",
      " 'policies': {'practices': 1.0},\n",
      " 'qualified': {'qualified': 0.96},\n",
      " 'time': {'time': 0.99},\n",
      " 'requirements': {'requirements': 1.0},\n",
      " 'knowledge': {'knowledge': 0.68}}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "page_summaries = {}\n",
    "with open(\"../data/strapi-page-summaries.json\") as f:\n",
    "    for page in json.load(f):\n",
    "        if page[\"PageSummary\"]:\n",
    "            # print(page[\"PageSummary\"])\n",
    "            # page_summaries[page[\"Slug\"]] = page[\"PageSummary\"]\n",
    "            print(page[\"Slug\"])\n",
    "            print(\"=\"*80)\n",
    "            cloze_text, answers, preds = generator.generate_cloze(page[\"PageSummary\"], num_blanks=6)\n",
    "            print(\"Cloze text:\")\n",
    "            print(cloze_text)\n",
    "            print(\"\\nAnswers:\")\n",
    "            answer_dict = {answer: {word: round(prob,2) for word, prob in pred.items()} for answer, pred in zip(answers, preds)}\n",
    "            pp(answer_dict)\n",
    "            print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a5827-4f91-4fef-bf8f-e162ed857c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
